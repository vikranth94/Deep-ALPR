{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from  natsort import natsorted\n",
    "import imageio\n",
    "import re\n",
    "import time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input, GRU, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, Bidirectional, Permute, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LambdaCallback\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras import backend as K\n",
    "from keras.models import load_model, Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import editdistance\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'ALPR_CNN'\n",
    "data_dir = 'Data'\n",
    "data_dir_2 = 'Data/dataset_1'\n",
    "model_dir = 'Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(data_dir, folder_name):\n",
    "    try:\n",
    "        print('Loading numpy')\n",
    "        X = np.load(os.path.join(data_dir,'X_{}.npy'.format(folder_name)))\n",
    "        y = np.load(os.path.join(data_dir,'y_{}.npy'.format(folder_name)))\n",
    "\n",
    "    except:\n",
    "        print('Loading images')\n",
    "        image_list = []\n",
    "        labels = []\n",
    "        pictures_dir = os.path.join(data_dir, folder_name)\n",
    "        names = [ d for d in os.listdir( pictures_dir ) if d.endswith( '.jpg') ]\n",
    "        names = natsorted(names)\n",
    "        for image in names:\n",
    "            image_list.append(imageio.imread(os.path.join(pictures_dir, image)))\n",
    "            label = re.split('[._]', image)\n",
    "            labels.append(label[0][2:])\n",
    "            print(label[0][2:])\n",
    "        X = np.stack(image_list, axis=0)\n",
    "        y = np.array(labels)\n",
    "        np.save(os.path.join(data_dir,'X_{}'.format(folder_name)),X)\n",
    "        np.save(os.path.join(data_dir,'y_{}'.format(folder_name)),y)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def prepare_dataset_2(data_dir, folder_name):\n",
    "    try:\n",
    "        print('Loading numpy')\n",
    "        X = np.load(os.path.join(data_dir,'X_{}.npy'.format(folder_name)))\n",
    "        y = np.load(os.path.join(data_dir,'y_{}.npy'.format(folder_name)))\n",
    "\n",
    "    except:\n",
    "        print('Loading images')\n",
    "        image_list = []\n",
    "        labels = []\n",
    "        pictures_dir = os.path.join(data_dir, folder_name)\n",
    "        names = [ d for d in os.listdir( pictures_dir ) if d.endswith( '.jpg') ]\n",
    "        names = natsorted(names)\n",
    "        for image in names:\n",
    "            image_list.append(imageio.imread(os.path.join(pictures_dir, image)))\n",
    "            label = re.split('[._]', image)\n",
    "            labels.append(label[1])\n",
    "            print(label[1])\n",
    "        X = np.stack(image_list, axis=0)\n",
    "        y = np.array(labels)\n",
    "        np.save(os.path.join(data_dir,'X_{}'.format(folder_name)),X)\n",
    "        np.save(os.path.join(data_dir,'y_{}'.format(folder_name)),y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading numpy\n",
      "(3921, 100, 160, 3)\n",
      "(3921,)\n"
     ]
    }
   ],
   "source": [
    "X1,y1 = prepare_dataset(data_dir, 'resized')\n",
    "print(X1.shape)\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading numpy\n",
      "(300, 100, 160, 3)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "X2,y2 = prepare_dataset_2(data_dir_2, 'Resized')\n",
    "print(X2.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4221, 100, 160, 3)\n",
      "(4221,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((X1,X2), axis=0)\n",
    "y_train = np.concatenate((y1,y2), axis=0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading numpy\n",
      "(1749, 100, 160, 3)\n",
      "(1749,)\n"
     ]
    }
   ],
   "source": [
    "X,y = prepare_dataset_2(data_dir_2, 'Resized_test')\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X_train = X_train[indices]\n",
    "y_train = y_train[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "X = X[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 1200\n",
    "X_test = X[:z]\n",
    "X_val = X[z:]\n",
    "y_test = y[:z]\n",
    "y_val = y[z:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'^[A-Z0-9 ]+$'\n",
    "alphabet = u'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation of characters to unique integer values\n",
    "def text_to_labels(text):\n",
    "    ret = []\n",
    "    for char in text:\n",
    "        ret.append(alphabet.find(char))\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Reverse translation of numerical classes back to characters\n",
    "def labels_to_text(labels):\n",
    "    ret = []\n",
    "    for c in labels:\n",
    "        if c == len(alphabet):  # CTC Blank\n",
    "            ret.append(\"\")\n",
    "        else:\n",
    "            ret.append(alphabet[c])\n",
    "    return \"\".join(ret)\n",
    "\n",
    "\n",
    "# only a-z and space..probably not to difficult\n",
    "# to expand to uppercase and symbols\n",
    "\n",
    "def is_valid_str(in_str):\n",
    "    search = re.compile(regex, re.UNICODE).search\n",
    "    return bool(search(in_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing 7 label plates\n",
    "mylen = np.vectorize(len)\n",
    "\n",
    "count = mylen(y_train)\n",
    "X_train = np.delete(X_train, np.where(count!=6)[0], axis=0 )\n",
    "y_train = np.delete(y_train, np.where(count!=6)[0], axis=0 )\n",
    "\n",
    "count = mylen(y_val)\n",
    "X_val = np.delete(X_val, np.where(count!=6)[0], axis=0 )\n",
    "y_val = np.delete(y_val, np.where(count!=6)[0], axis=0 )\n",
    "\n",
    "count = mylen(y_test)\n",
    "X_test = np.delete(X_test, np.where(count!=6)[0], axis=0 )\n",
    "y_test = np.delete(y_test, np.where(count!=6)[0], axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4215, 100, 160, 3)\n",
      "(4215,)\n",
      "(543, 100, 160, 3)\n",
      "(543,)\n",
      "(1197, 100, 160, 3)\n",
      "(1197,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_labels(labels):\n",
    "    y_coded = []\n",
    "    for l in labels:\n",
    "        y_coded.append(text_to_labels(l))\n",
    "    return np.array(y_coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4215, 6)\n",
      "(543, 6)\n",
      "(1197, 6)\n"
     ]
    }
   ],
   "source": [
    "y_train_coded = code_labels(y_train)\n",
    "y_val_coded = code_labels(y_val)\n",
    "y_test_coded = code_labels(y_test)\n",
    "print(y_train_coded.shape)\n",
    "print(y_val_coded.shape)\n",
    "print(y_test_coded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 36\n",
    "#Labels to binary\n",
    "y_train_0 = keras.utils.to_categorical(y_train_coded[:,0],num_classes)\n",
    "y_train_1 = keras.utils.to_categorical(y_train_coded[:,1],num_classes)\n",
    "y_train_2 = keras.utils.to_categorical(y_train_coded[:,2],num_classes)\n",
    "y_train_3 = keras.utils.to_categorical(y_train_coded[:,3],num_classes)\n",
    "y_train_4 = keras.utils.to_categorical(y_train_coded[:,4],num_classes)\n",
    "y_train_5 = keras.utils.to_categorical(y_train_coded[:,5],num_classes)\n",
    "\n",
    "y_val_0 = keras.utils.to_categorical(y_val_coded[:,0],num_classes)\n",
    "y_val_1 = keras.utils.to_categorical(y_val_coded[:,1],num_classes)\n",
    "y_val_2 = keras.utils.to_categorical(y_val_coded[:,2],num_classes)\n",
    "y_val_3 = keras.utils.to_categorical(y_val_coded[:,3],num_classes)\n",
    "y_val_4 = keras.utils.to_categorical(y_val_coded[:,4],num_classes)\n",
    "y_val_5 = keras.utils.to_categorical(y_val_coded[:,5],num_classes)\n",
    "\n",
    "y_test_0 = keras.utils.to_categorical(y_test_coded[:,0],num_classes)\n",
    "y_test_1 = keras.utils.to_categorical(y_test_coded[:,1],num_classes)\n",
    "y_test_2 = keras.utils.to_categorical(y_test_coded[:,2],num_classes)\n",
    "y_test_3 = keras.utils.to_categorical(y_test_coded[:,3],num_classes)\n",
    "y_test_4 = keras.utils.to_categorical(y_test_coded[:,4],num_classes)\n",
    "y_test_5 = keras.utils.to_categorical(y_test_coded[:,5],num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w = 100\n",
    "# Input Parameters\n",
    "img_h = 160\n",
    "# Network parameters\n",
    "conv_filters = 64\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "rnn_size = 64\n",
    "minibatch_size = 128\n",
    "unique_tokens = 37\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_w, img_h)\n",
    "else:\n",
    "    input_shape = (img_w, img_h, 3)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "act = 'relu'\n",
    "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv1')(input_data)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv2')(inner)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "# cuts down input size going into RNN:\n",
    "inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "# Two layers of bidirectional GRUs\n",
    "# GRU seems to work as well, if not better than LSTM:\n",
    "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "gru1_merged = add([gru_1, gru_1b])\n",
    "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "# transforms RNN output to character activations:\n",
    "inner = Dense(unique_tokens, kernel_initializer='he_normal',\n",
    "              name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "Model(inputs=input_data, outputs=y_pred).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model_1(input_shape, p=0.3):\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    x = Conv2D(32, kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   input_shape=input_shape,\n",
    "                   padding='same', name='Conv_1')(input_data)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_1')(x)\n",
    "    x = BatchNormalization(name='Bn_1')(x)\n",
    "    x = Dropout(p, name='Drop_1')(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_2')(x)\n",
    "    x = BatchNormalization(name='Bn_2')(x)\n",
    "    x = Dropout(p, name='Drop_2')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_3')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_3')(x)\n",
    "    x = BatchNormalization(name='Bn_3')(x)\n",
    "    x = Dropout(p, name='Drop_3')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_4')(x)\n",
    "    x = BatchNormalization(name='Bn_4')(x)\n",
    "    x = Dropout(p, name='Drop_4')(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_5')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_5')(x)\n",
    "    x = BatchNormalization(name='Bn_5')(x)\n",
    "    x = Dropout(p, name='Drop_5')(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_6')(x)\n",
    "    x = BatchNormalization(name='Bn_6')(x)\n",
    "    x = Dropout(p, name='Drop_6')(x)\n",
    "    x = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_7')(x)\n",
    "    x = BatchNormalization(name='Bn_7')(x)\n",
    "    x = Dropout(p, name='Drop_7')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu', name='dense_1')(x)\n",
    "    x = BatchNormalization(name='Bn_8')(x)\n",
    "    x = Dropout(p, name='Drop_8')(x)\n",
    "\n",
    "    #output\n",
    "    d1 = Dense(num_classes, activation='softmax', name='dense_out_1')(x)\n",
    "    d2 = Dense(num_classes, activation='softmax', name='dense_out_2' )(x)\n",
    "    d3 = Dense(num_classes, activation='softmax', name='dense_out_3')(x)\n",
    "    d4 = Dense(num_classes, activation='softmax', name='dense_out_4')(x)\n",
    "    d5 = Dense(num_classes, activation='softmax', name='dense_out_5')(x)\n",
    "    d6 = Dense(num_classes, activation='softmax', name='dense_out_6')(x)\n",
    "    model = Model(input_data, [d1,d2,d3,d4,d5,d6])\n",
    "    return model\n",
    "\n",
    "\n",
    "def CNN_model_2(input_shape, p=0.3):\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    x = Conv2D(32, kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   input_shape=input_shape,\n",
    "                   padding='same', name='Conv_1')(input_data)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_1')(x)\n",
    "    x = BatchNormalization(name='Bn_1')(x)\n",
    "    x = Dropout(p, name='Drop_1')(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_2')(x)\n",
    "    x = BatchNormalization(name='Bn_2')(x)\n",
    "    x = Dropout(p, name='Drop_2')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_3')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_3')(x)\n",
    "    x = BatchNormalization(name='Bn_3')(x)\n",
    "    x = Dropout(p, name='Drop_3')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_4')(x)\n",
    "    x = BatchNormalization(name='Bn_4')(x)\n",
    "    x = Dropout(p, name='Drop_4')(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_5')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_5')(x)\n",
    "    x = BatchNormalization(name='Bn_5')(x)\n",
    "    x = Dropout(p, name='Drop_5')(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_6')(x)\n",
    "    x = BatchNormalization(name='Bn_6')(x)\n",
    "    x = Dropout(p, name='Drop_6')(x)\n",
    "    x = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_7')(x)\n",
    "    x = BatchNormalization(name='Bn_7')(x)\n",
    "    x = Dropout(p, name='Drop_7')(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "\n",
    "    #output\n",
    "    d1= Dense(128, activation='relu', name='dense_d1')(x)\n",
    "    d1 = BatchNormalization(name='Bn_d1')(d1)\n",
    "    d1 = Dropout(p, name='Drop_d1')(d1)\n",
    "    d1 = Dense(num_classes, activation='softmax', name='dense_out_1')(d1)\n",
    "    d2 = Dense(128, activation='relu', name='dense_d2')(x)\n",
    "    d2 = BatchNormalization(name='Bn_d2')(d2)\n",
    "    d2 = Dropout(p, name='Drop_d2')(d2)\n",
    "    d2 = Dense(num_classes, activation='softmax', name='dense_out_2' )(d2)\n",
    "    d3 = Dense(128, activation='relu', name='dense_d3')(x)\n",
    "    d3 = BatchNormalization(name='Bn_d3')(d3)\n",
    "    d3 = Dropout(p, name='Drop_d3')(d3)\n",
    "    d3 = Dense(num_classes, activation='softmax', name='dense_out_3')(d3)\n",
    "    d4 = Dense(128, activation='relu', name='dense_d4')(x)\n",
    "    d4 = BatchNormalization(name='Bn_d4')(d4)\n",
    "    d4 = Dropout(p, name='Drop_d4')(d4)\n",
    "    d4 = Dense(num_classes, activation='softmax', name='dense_out_4')(d4)\n",
    "    d5 = Dense(128, activation='relu', name='dense_d5')(x)\n",
    "    d5 = BatchNormalization(name='Bn_d5')(d5)\n",
    "    d5 = Dropout(p, name='Drop_d5')(d5)\n",
    "    d5 = Dense(num_classes, activation='softmax', name='dense_out_5')(d5)\n",
    "    d6 = Dense(128, activation='relu', name='dense_d6')(x)\n",
    "    d6 = BatchNormalization(name='Bn_d6')(d6)\n",
    "    d6 = Dropout(p, name='Drop_d6')(d6)\n",
    "    d6 = Dense(num_classes, activation='softmax', name='dense_out_6')(d6)\n",
    "    model = Model(input_data, [d1,d2,d3,d4,d5,d6])\n",
    "    return model\n",
    "\n",
    "def ConvLSTM_model_1(input_shape, p=0.3):\n",
    "    input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    x = Conv2D(32, kernel_size=(3, 3),\n",
    "                   activation='relu',\n",
    "                   input_shape=input_shape,\n",
    "                   padding='same', name='Conv_1')(input_data)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_1')(x)\n",
    "    x = BatchNormalization(name='Bn_1')(x)\n",
    "    x = Dropout(p, name='Drop_1')(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_2')(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_2')(x)\n",
    "    x = BatchNormalization(name='Bn_2')(x)\n",
    "    x = Dropout(p, name='Drop_2')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_3')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_3')(x)\n",
    "    x = BatchNormalization(name='Bn_3')(x)\n",
    "    x = Dropout(p, name='Drop_3')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_4')(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_4')(x)\n",
    "    x = BatchNormalization(name='Bn_4')(x)\n",
    "    x = Dropout(p, name='Drop_4')(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_5')(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_5')(x)\n",
    "    x = BatchNormalization(name='Bn_5')(x)\n",
    "    x = Dropout(p, name='Drop_5')(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_6')(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_6')(x)\n",
    "    x = BatchNormalization(name='Bn_6')(x)\n",
    "    x = Dropout(p, name='Drop_6')(x)\n",
    "    x = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_7')(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_7')(x)\n",
    "    x = BatchNormalization(name='Bn_7')(x)\n",
    "    x = Dropout(p, name='Drop_7')(x)\n",
    "    x = Permute((2, 1, 3), name='Permute_1')(x)  # for swap-dimension\n",
    "    x = Reshape((-1, 16 * (img_w // (2 ** 2))), name='Reshape_1')(x)\n",
    "    x = Dense(32, activation='relu', name='dense1')(x)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True, stateful=False, name='Lstm_1'))(x)\n",
    "    x = BatchNormalization(name='Bn_LSTM1')(x)\n",
    "    x = Bidirectional(LSTM(32, return_sequences=True, stateful=False, name='Lstm_1'))(x)\n",
    "    x = BatchNormalization(name='Bn_LSTM2')(x)\n",
    "    x = Dropout(p, name='Drop_14')(x)\n",
    "    x = Dense(128, activation='relu', name='dense_2')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu', name='dense_1')(x)\n",
    "    x = BatchNormalization(name='Bn_8')(x)\n",
    "    x = Dropout(p, name='Drop_8')(x)\n",
    "\n",
    "    #output\n",
    "    d1 = Dense(num_classes, activation='softmax', name='dense_out_1')(x)\n",
    "    d2 = Dense(num_classes, activation='softmax', name='dense_out_2' )(x)\n",
    "    d3 = Dense(num_classes, activation='softmax', name='dense_out_3')(x)\n",
    "    d4 = Dense(num_classes, activation='softmax', name='dense_out_4')(x)\n",
    "    d5 = Dense(num_classes, activation='softmax', name='dense_out_5')(x)\n",
    "    d6 = Dense(num_classes, activation='softmax', name='dense_out_6')(x)\n",
    "    model = Model(input_data, [d1,d2,d3,d4,d5,d6])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 100, 160, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 100, 160, 32) 896         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Max_pool_1 (MaxPooling2D)       (None, 50, 80, 32)   0           Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Bn_1 (BatchNormalization)       (None, 50, 80, 32)   128         Max_pool_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Drop_1 (Dropout)                (None, 50, 80, 32)   0           Bn_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_2 (Conv2D)                 (None, 50, 80, 64)   18496       Drop_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Bn_2 (BatchNormalization)       (None, 50, 80, 64)   256         Conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Drop_2 (Dropout)                (None, 50, 80, 64)   0           Bn_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_3 (Conv2D)                 (None, 50, 80, 128)  73856       Drop_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Max_pool_3 (MaxPooling2D)       (None, 25, 40, 128)  0           Conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Bn_3 (BatchNormalization)       (None, 25, 40, 128)  512         Max_pool_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Drop_3 (Dropout)                (None, 25, 40, 128)  0           Bn_3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_4 (Conv2D)                 (None, 25, 40, 128)  147584      Drop_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Bn_4 (BatchNormalization)       (None, 25, 40, 128)  512         Conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Drop_4 (Dropout)                (None, 25, 40, 128)  0           Bn_4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_5 (Conv2D)                 (None, 25, 40, 64)   73792       Drop_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Bn_5 (BatchNormalization)       (None, 25, 40, 64)   256         Conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Drop_5 (Dropout)                (None, 25, 40, 64)   0           Bn_5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_6 (Conv2D)                 (None, 25, 40, 32)   18464       Drop_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Bn_6 (BatchNormalization)       (None, 25, 40, 32)   128         Conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Drop_6 (Dropout)                (None, 25, 40, 32)   0           Bn_6[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv_7 (Conv2D)                 (None, 25, 40, 16)   4624        Drop_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Bn_7 (BatchNormalization)       (None, 25, 40, 16)   64          Conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Drop_7 (Dropout)                (None, 25, 40, 16)   0           Bn_7[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Permute_1 (Permute)             (None, 40, 25, 16)   0           Drop_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Reshape_1 (Reshape)             (None, 40, 400)      0           Permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 40, 32)       12832       Reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 40, 64)       16640       dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Bn_LSTM1 (BatchNormalization)   (None, 40, 64)       256         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 40, 64)       24832       Bn_LSTM1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Bn_LSTM2 (BatchNormalization)   (None, 40, 64)       256         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Drop_14 (Dropout)               (None, 40, 64)       0           Bn_LSTM2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 40, 128)      8320        Drop_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 5120)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          655488      flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Bn_8 (BatchNormalization)       (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Drop_8 (Dropout)                (None, 128)          0           Bn_8[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_out_1 (Dense)             (None, 36)           4644        Drop_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_out_2 (Dense)             (None, 36)           4644        Drop_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_out_3 (Dense)             (None, 36)           4644        Drop_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_out_4 (Dense)             (None, 36)           4644        Drop_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_out_5 (Dense)             (None, 36)           4644        Drop_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_out_6 (Dense)             (None, 36)           4644        Drop_8[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,086,568\n",
      "Trainable params: 1,085,128\n",
      "Non-trainable params: 1,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ConvLSTM_model_1(input_shape, p=0.3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(epoch, logs):\n",
    "    global best_val_acc\n",
    "    global chk_path\n",
    "    val_dense_out_1_acc = logs['val_dense_out_1_acc']\n",
    "    val_dense_out_2_acc = logs['val_dense_out_2_acc']\n",
    "    val_dense_out_3_acc = logs['val_dense_out_3_acc']\n",
    "    val_dense_out_4_acc = logs['val_dense_out_4_acc']\n",
    "    val_dense_out_5_acc = logs['val_dense_out_5_acc']\n",
    "    val_dense_out_6_acc = logs['val_dense_out_6_acc']\n",
    "    val_acc = np.mean([val_dense_out_1_acc, val_dense_out_2_acc, val_dense_out_3_acc,\n",
    "                      val_dense_out_4_acc, val_dense_out_5_acc, val_dense_out_6_acc])\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        print('Avg_val_acc imporved from {} to {}'.format(best_val_acc, val_acc))\n",
    "        print('Saved model {}'.format(chk_path))\n",
    "        best_val_acc = val_acc\n",
    "        model.save(chk_path)\n",
    "\n",
    "#callbacks = [LambdaCallback(on_epoch_end=saveModel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4215 samples, validate on 543 samples\n",
      "Epoch 1/300\n",
      "4215/4215 [==============================] - 44s 10ms/step - loss: 0.3200 - dense_out_1_loss: 0.0531 - dense_out_2_loss: 0.0660 - dense_out_3_loss: 0.0560 - dense_out_4_loss: 0.0352 - dense_out_5_loss: 0.0467 - dense_out_6_loss: 0.0630 - dense_out_1_acc: 0.9839 - dense_out_2_acc: 0.9789 - dense_out_3_acc: 0.9820 - dense_out_4_acc: 0.9884 - dense_out_5_acc: 0.9867 - dense_out_6_acc: 0.9817 - val_loss: 4.3592 - val_dense_out_1_loss: 1.0417 - val_dense_out_2_loss: 1.0747 - val_dense_out_3_loss: 0.1467 - val_dense_out_4_loss: 0.0960 - val_dense_out_5_loss: 0.7870 - val_dense_out_6_loss: 1.2131 - val_dense_out_1_acc: 0.7551 - val_dense_out_2_acc: 0.7514 - val_dense_out_3_acc: 0.9650 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8103 - val_dense_out_6_acc: 0.7403\n",
      "Avg_val_acc imporved from 0 to 0.8345610791367939\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 2/300\n",
      "4215/4215 [==============================] - 37s 9ms/step - loss: 0.3296 - dense_out_1_loss: 0.0673 - dense_out_2_loss: 0.0583 - dense_out_3_loss: 0.0440 - dense_out_4_loss: 0.0381 - dense_out_5_loss: 0.0613 - dense_out_6_loss: 0.0606 - dense_out_1_acc: 0.9803 - dense_out_2_acc: 0.9810 - dense_out_3_acc: 0.9846 - dense_out_4_acc: 0.9879 - dense_out_5_acc: 0.9805 - dense_out_6_acc: 0.9805 - val_loss: 4.5695 - val_dense_out_1_loss: 1.0207 - val_dense_out_2_loss: 1.1450 - val_dense_out_3_loss: 0.1354 - val_dense_out_4_loss: 0.1168 - val_dense_out_5_loss: 0.8516 - val_dense_out_6_loss: 1.3001 - val_dense_out_1_acc: 0.7698 - val_dense_out_2_acc: 0.7293 - val_dense_out_3_acc: 0.9650 - val_dense_out_4_acc: 0.9834 - val_dense_out_5_acc: 0.8361 - val_dense_out_6_acc: 0.7403\n",
      "Avg_val_acc imporved from 0.8345610791367939 to 0.8373235085941372\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 3/300\n",
      "4215/4215 [==============================] - 37s 9ms/step - loss: 0.3098 - dense_out_1_loss: 0.0661 - dense_out_2_loss: 0.0583 - dense_out_3_loss: 0.0519 - dense_out_4_loss: 0.0394 - dense_out_5_loss: 0.0398 - dense_out_6_loss: 0.0544 - dense_out_1_acc: 0.9784 - dense_out_2_acc: 0.9817 - dense_out_3_acc: 0.9820 - dense_out_4_acc: 0.9886 - dense_out_5_acc: 0.9879 - dense_out_6_acc: 0.9813 - val_loss: 4.7489 - val_dense_out_1_loss: 1.0310 - val_dense_out_2_loss: 1.2787 - val_dense_out_3_loss: 0.1488 - val_dense_out_4_loss: 0.1011 - val_dense_out_5_loss: 0.9221 - val_dense_out_6_loss: 1.2672 - val_dense_out_1_acc: 0.7661 - val_dense_out_2_acc: 0.7385 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8140 - val_dense_out_6_acc: 0.7440\n",
      "Epoch 4/300\n",
      "4215/4215 [==============================] - 38s 9ms/step - loss: 0.3169 - dense_out_1_loss: 0.0695 - dense_out_2_loss: 0.0617 - dense_out_3_loss: 0.0476 - dense_out_4_loss: 0.0393 - dense_out_5_loss: 0.0413 - dense_out_6_loss: 0.0576 - dense_out_1_acc: 0.9784 - dense_out_2_acc: 0.9796 - dense_out_3_acc: 0.9853 - dense_out_4_acc: 0.9858 - dense_out_5_acc: 0.9879 - dense_out_6_acc: 0.9801 - val_loss: 5.0791 - val_dense_out_1_loss: 1.1344 - val_dense_out_2_loss: 1.2156 - val_dense_out_3_loss: 0.1355 - val_dense_out_4_loss: 0.1556 - val_dense_out_5_loss: 0.9812 - val_dense_out_6_loss: 1.4568 - val_dense_out_1_acc: 0.7422 - val_dense_out_2_acc: 0.7403 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9779 - val_dense_out_5_acc: 0.7956 - val_dense_out_6_acc: 0.7311\n",
      "Epoch 5/300\n",
      "4215/4215 [==============================] - 38s 9ms/step - loss: 0.3004 - dense_out_1_loss: 0.0628 - dense_out_2_loss: 0.0538 - dense_out_3_loss: 0.0485 - dense_out_4_loss: 0.0384 - dense_out_5_loss: 0.0449 - dense_out_6_loss: 0.0520 - dense_out_1_acc: 0.9808 - dense_out_2_acc: 0.9836 - dense_out_3_acc: 0.9843 - dense_out_4_acc: 0.9877 - dense_out_5_acc: 0.9848 - dense_out_6_acc: 0.9834 - val_loss: 4.7569 - val_dense_out_1_loss: 1.0000 - val_dense_out_2_loss: 1.1937 - val_dense_out_3_loss: 0.1050 - val_dense_out_4_loss: 0.1238 - val_dense_out_5_loss: 0.9504 - val_dense_out_6_loss: 1.3840 - val_dense_out_1_acc: 0.7845 - val_dense_out_2_acc: 0.7238 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9797 - val_dense_out_5_acc: 0.8214 - val_dense_out_6_acc: 0.7403\n",
      "Avg_val_acc imporved from 0.8373235085941372 to 0.8373235117225577\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 6/300\n",
      "4215/4215 [==============================] - 37s 9ms/step - loss: 0.3449 - dense_out_1_loss: 0.0633 - dense_out_2_loss: 0.0644 - dense_out_3_loss: 0.0511 - dense_out_4_loss: 0.0522 - dense_out_5_loss: 0.0532 - dense_out_6_loss: 0.0606 - dense_out_1_acc: 0.9815 - dense_out_2_acc: 0.9789 - dense_out_3_acc: 0.9839 - dense_out_4_acc: 0.9839 - dense_out_5_acc: 0.9810 - dense_out_6_acc: 0.9789 - val_loss: 4.4398 - val_dense_out_1_loss: 0.9671 - val_dense_out_2_loss: 1.1696 - val_dense_out_3_loss: 0.1020 - val_dense_out_4_loss: 0.1228 - val_dense_out_5_loss: 0.7910 - val_dense_out_6_loss: 1.2873 - val_dense_out_1_acc: 0.7716 - val_dense_out_2_acc: 0.7532 - val_dense_out_3_acc: 0.9797 - val_dense_out_4_acc: 0.9834 - val_dense_out_5_acc: 0.8269 - val_dense_out_6_acc: 0.7293\n",
      "Avg_val_acc imporved from 0.8373235117225577 to 0.8406998163136037\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 7/300\n",
      "4215/4215 [==============================] - 37s 9ms/step - loss: 0.2969 - dense_out_1_loss: 0.0527 - dense_out_2_loss: 0.0620 - dense_out_3_loss: 0.0478 - dense_out_4_loss: 0.0329 - dense_out_5_loss: 0.0458 - dense_out_6_loss: 0.0558 - dense_out_1_acc: 0.9860 - dense_out_2_acc: 0.9836 - dense_out_3_acc: 0.9851 - dense_out_4_acc: 0.9905 - dense_out_5_acc: 0.9855 - dense_out_6_acc: 0.9820 - val_loss: 4.3282 - val_dense_out_1_loss: 0.9168 - val_dense_out_2_loss: 1.1568 - val_dense_out_3_loss: 0.1435 - val_dense_out_4_loss: 0.1044 - val_dense_out_5_loss: 0.7494 - val_dense_out_6_loss: 1.2573 - val_dense_out_1_acc: 0.7827 - val_dense_out_2_acc: 0.7551 - val_dense_out_3_acc: 0.9669 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8379 - val_dense_out_6_acc: 0.7311\n",
      "Avg_val_acc imporved from 0.8406998163136037 to 0.8434622460819593\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 8/300\n",
      "4215/4215 [==============================] - 37s 9ms/step - loss: 0.2865 - dense_out_1_loss: 0.0577 - dense_out_2_loss: 0.0530 - dense_out_3_loss: 0.0425 - dense_out_4_loss: 0.0388 - dense_out_5_loss: 0.0421 - dense_out_6_loss: 0.0524 - dense_out_1_acc: 0.9822 - dense_out_2_acc: 0.9832 - dense_out_3_acc: 0.9848 - dense_out_4_acc: 0.9879 - dense_out_5_acc: 0.9872 - dense_out_6_acc: 0.9822 - val_loss: 4.5471 - val_dense_out_1_loss: 0.9997 - val_dense_out_2_loss: 1.0862 - val_dense_out_3_loss: 0.1049 - val_dense_out_4_loss: 0.1300 - val_dense_out_5_loss: 0.8876 - val_dense_out_6_loss: 1.3386 - val_dense_out_1_acc: 0.7661 - val_dense_out_2_acc: 0.7680 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8103 - val_dense_out_6_acc: 0.7330\n",
      "Epoch 9/300\n",
      "4215/4215 [==============================] - 37s 9ms/step - loss: 0.2856 - dense_out_1_loss: 0.0539 - dense_out_2_loss: 0.0549 - dense_out_3_loss: 0.0429 - dense_out_4_loss: 0.0359 - dense_out_5_loss: 0.0518 - dense_out_6_loss: 0.0462 - dense_out_1_acc: 0.9843 - dense_out_2_acc: 0.9824 - dense_out_3_acc: 0.9848 - dense_out_4_acc: 0.9896 - dense_out_5_acc: 0.9836 - dense_out_6_acc: 0.9858 - val_loss: 4.1744 - val_dense_out_1_loss: 0.9837 - val_dense_out_2_loss: 1.0077 - val_dense_out_3_loss: 0.0893 - val_dense_out_4_loss: 0.0892 - val_dense_out_5_loss: 0.7993 - val_dense_out_6_loss: 1.2053 - val_dense_out_1_acc: 0.7772 - val_dense_out_2_acc: 0.7716 - val_dense_out_3_acc: 0.9797 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8306 - val_dense_out_6_acc: 0.7422\n",
      "Avg_val_acc imporved from 0.8434622460819593 to 0.8477593589187621\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 10/300\n",
      "4215/4215 [==============================] - 37s 9ms/step - loss: 0.3045 - dense_out_1_loss: 0.0592 - dense_out_2_loss: 0.0581 - dense_out_3_loss: 0.0506 - dense_out_4_loss: 0.0369 - dense_out_5_loss: 0.0471 - dense_out_6_loss: 0.0527 - dense_out_1_acc: 0.9808 - dense_out_2_acc: 0.9832 - dense_out_3_acc: 0.9827 - dense_out_4_acc: 0.9884 - dense_out_5_acc: 0.9836 - dense_out_6_acc: 0.9798 - val_loss: 4.3857 - val_dense_out_1_loss: 1.0576 - val_dense_out_2_loss: 1.0798 - val_dense_out_3_loss: 0.1552 - val_dense_out_4_loss: 0.0907 - val_dense_out_5_loss: 0.7759 - val_dense_out_6_loss: 1.2266 - val_dense_out_1_acc: 0.7698 - val_dense_out_2_acc: 0.7624 - val_dense_out_3_acc: 0.9632 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8287 - val_dense_out_6_acc: 0.7532\n",
      "Epoch 11/300\n",
      "4215/4215 [==============================] - 37s 9ms/step - loss: 0.2916 - dense_out_1_loss: 0.0545 - dense_out_2_loss: 0.0580 - dense_out_3_loss: 0.0502 - dense_out_4_loss: 0.0431 - dense_out_5_loss: 0.0396 - dense_out_6_loss: 0.0464 - dense_out_1_acc: 0.9827 - dense_out_2_acc: 0.9843 - dense_out_3_acc: 0.9851 - dense_out_4_acc: 0.9862 - dense_out_5_acc: 0.9893 - dense_out_6_acc: 0.9872 - val_loss: 4.2291 - val_dense_out_1_loss: 0.9679 - val_dense_out_2_loss: 1.1031 - val_dense_out_3_loss: 0.1222 - val_dense_out_4_loss: 0.0971 - val_dense_out_5_loss: 0.7317 - val_dense_out_6_loss: 1.2070 - val_dense_out_1_acc: 0.7937 - val_dense_out_2_acc: 0.7532 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8435 - val_dense_out_6_acc: 0.7587\n",
      "Avg_val_acc imporved from 0.8477593589187621 to 0.8514426035007281\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 12/300\n",
      "4215/4215 [==============================] - 37s 9ms/step - loss: 0.2831 - dense_out_1_loss: 0.0601 - dense_out_2_loss: 0.0575 - dense_out_3_loss: 0.0442 - dense_out_4_loss: 0.0307 - dense_out_5_loss: 0.0399 - dense_out_6_loss: 0.0507 - dense_out_1_acc: 0.9829 - dense_out_2_acc: 0.9824 - dense_out_3_acc: 0.9867 - dense_out_4_acc: 0.9898 - dense_out_5_acc: 0.9872 - dense_out_6_acc: 0.9827 - val_loss: 4.1713 - val_dense_out_1_loss: 0.9529 - val_dense_out_2_loss: 1.0454 - val_dense_out_3_loss: 0.0693 - val_dense_out_4_loss: 0.0939 - val_dense_out_5_loss: 0.7780 - val_dense_out_6_loss: 1.2317 - val_dense_out_1_acc: 0.7808 - val_dense_out_2_acc: 0.7587 - val_dense_out_3_acc: 0.9797 - val_dense_out_4_acc: 0.9834 - val_dense_out_5_acc: 0.8361 - val_dense_out_6_acc: 0.7514\n",
      "Epoch 13/300\n",
      "4215/4215 [==============================] - 36s 9ms/step - loss: 0.2544 - dense_out_1_loss: 0.0481 - dense_out_2_loss: 0.0508 - dense_out_3_loss: 0.0390 - dense_out_4_loss: 0.0301 - dense_out_5_loss: 0.0436 - dense_out_6_loss: 0.0429 - dense_out_1_acc: 0.9858 - dense_out_2_acc: 0.9839 - dense_out_3_acc: 0.9884 - dense_out_4_acc: 0.9903 - dense_out_5_acc: 0.9874 - dense_out_6_acc: 0.9865 - val_loss: 4.1273 - val_dense_out_1_loss: 0.9910 - val_dense_out_2_loss: 1.0009 - val_dense_out_3_loss: 0.0874 - val_dense_out_4_loss: 0.0866 - val_dense_out_5_loss: 0.7436 - val_dense_out_6_loss: 1.2177 - val_dense_out_1_acc: 0.7808 - val_dense_out_2_acc: 0.7790 - val_dense_out_3_acc: 0.9779 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8600 - val_dense_out_6_acc: 0.7643\n",
      "Avg_val_acc imporved from 0.8514426035007281 to 0.8581952060966714\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 14/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2892 - dense_out_1_loss: 0.0615 - dense_out_2_loss: 0.0612 - dense_out_3_loss: 0.0381 - dense_out_4_loss: 0.0408 - dense_out_5_loss: 0.0441 - dense_out_6_loss: 0.0436 - dense_out_1_acc: 0.9813 - dense_out_2_acc: 0.9820 - dense_out_3_acc: 0.9903 - dense_out_4_acc: 0.9877 - dense_out_5_acc: 0.9855 - dense_out_6_acc: 0.9867 - val_loss: 4.1807 - val_dense_out_1_loss: 0.9087 - val_dense_out_2_loss: 1.1326 - val_dense_out_3_loss: 0.1253 - val_dense_out_4_loss: 0.0942 - val_dense_out_5_loss: 0.7089 - val_dense_out_6_loss: 1.2110 - val_dense_out_1_acc: 0.7974 - val_dense_out_2_acc: 0.7587 - val_dense_out_3_acc: 0.9632 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8490 - val_dense_out_6_acc: 0.7716\n",
      "Epoch 15/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2967 - dense_out_1_loss: 0.0614 - dense_out_2_loss: 0.0619 - dense_out_3_loss: 0.0495 - dense_out_4_loss: 0.0376 - dense_out_5_loss: 0.0407 - dense_out_6_loss: 0.0457 - dense_out_1_acc: 0.9810 - dense_out_2_acc: 0.9829 - dense_out_3_acc: 0.9841 - dense_out_4_acc: 0.9884 - dense_out_5_acc: 0.9891 - dense_out_6_acc: 0.9858 - val_loss: 4.1994 - val_dense_out_1_loss: 0.9155 - val_dense_out_2_loss: 1.1127 - val_dense_out_3_loss: 0.1175 - val_dense_out_4_loss: 0.0820 - val_dense_out_5_loss: 0.7867 - val_dense_out_6_loss: 1.1850 - val_dense_out_1_acc: 0.7919 - val_dense_out_2_acc: 0.7551 - val_dense_out_3_acc: 0.9705 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8453 - val_dense_out_6_acc: 0.7459\n",
      "Epoch 16/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2783 - dense_out_1_loss: 0.0461 - dense_out_2_loss: 0.0564 - dense_out_3_loss: 0.0552 - dense_out_4_loss: 0.0367 - dense_out_5_loss: 0.0418 - dense_out_6_loss: 0.0422 - dense_out_1_acc: 0.9862 - dense_out_2_acc: 0.9817 - dense_out_3_acc: 0.9841 - dense_out_4_acc: 0.9884 - dense_out_5_acc: 0.9858 - dense_out_6_acc: 0.9888 - val_loss: 4.0644 - val_dense_out_1_loss: 0.9212 - val_dense_out_2_loss: 1.0459 - val_dense_out_3_loss: 0.1624 - val_dense_out_4_loss: 0.1101 - val_dense_out_5_loss: 0.7554 - val_dense_out_6_loss: 1.0694 - val_dense_out_1_acc: 0.8029 - val_dense_out_2_acc: 0.7624 - val_dense_out_3_acc: 0.9650 - val_dense_out_4_acc: 0.9779 - val_dense_out_5_acc: 0.8508 - val_dense_out_6_acc: 0.7827\n",
      "Epoch 17/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2725 - dense_out_1_loss: 0.0512 - dense_out_2_loss: 0.0449 - dense_out_3_loss: 0.0455 - dense_out_4_loss: 0.0339 - dense_out_5_loss: 0.0442 - dense_out_6_loss: 0.0527 - dense_out_1_acc: 0.9843 - dense_out_2_acc: 0.9867 - dense_out_3_acc: 0.9865 - dense_out_4_acc: 0.9910 - dense_out_5_acc: 0.9893 - dense_out_6_acc: 0.9843 - val_loss: 4.2896 - val_dense_out_1_loss: 0.8931 - val_dense_out_2_loss: 1.0135 - val_dense_out_3_loss: 0.1172 - val_dense_out_4_loss: 0.1021 - val_dense_out_5_loss: 0.8653 - val_dense_out_6_loss: 1.2982 - val_dense_out_1_acc: 0.7845 - val_dense_out_2_acc: 0.7661 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8250 - val_dense_out_6_acc: 0.7422\n",
      "Epoch 18/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2637 - dense_out_1_loss: 0.0616 - dense_out_2_loss: 0.0428 - dense_out_3_loss: 0.0438 - dense_out_4_loss: 0.0364 - dense_out_5_loss: 0.0365 - dense_out_6_loss: 0.0426 - dense_out_1_acc: 0.9803 - dense_out_2_acc: 0.9879 - dense_out_3_acc: 0.9858 - dense_out_4_acc: 0.9893 - dense_out_5_acc: 0.9888 - dense_out_6_acc: 0.9874 - val_loss: 4.3896 - val_dense_out_1_loss: 0.9513 - val_dense_out_2_loss: 1.1057 - val_dense_out_3_loss: 0.1430 - val_dense_out_4_loss: 0.1102 - val_dense_out_5_loss: 0.8424 - val_dense_out_6_loss: 1.2370 - val_dense_out_1_acc: 0.7845 - val_dense_out_2_acc: 0.7440 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8361 - val_dense_out_6_acc: 0.7716\n",
      "Epoch 19/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2716 - dense_out_1_loss: 0.0465 - dense_out_2_loss: 0.0504 - dense_out_3_loss: 0.0556 - dense_out_4_loss: 0.0340 - dense_out_5_loss: 0.0372 - dense_out_6_loss: 0.0479 - dense_out_1_acc: 0.9851 - dense_out_2_acc: 0.9848 - dense_out_3_acc: 0.9822 - dense_out_4_acc: 0.9910 - dense_out_5_acc: 0.9870 - dense_out_6_acc: 0.9822 - val_loss: 4.7101 - val_dense_out_1_loss: 0.9995 - val_dense_out_2_loss: 1.0940 - val_dense_out_3_loss: 0.1361 - val_dense_out_4_loss: 0.1211 - val_dense_out_5_loss: 0.9471 - val_dense_out_6_loss: 1.4123 - val_dense_out_1_acc: 0.7790 - val_dense_out_2_acc: 0.7643 - val_dense_out_3_acc: 0.9779 - val_dense_out_4_acc: 0.9834 - val_dense_out_5_acc: 0.8122 - val_dense_out_6_acc: 0.7274\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2628 - dense_out_1_loss: 0.0518 - dense_out_2_loss: 0.0431 - dense_out_3_loss: 0.0422 - dense_out_4_loss: 0.0402 - dense_out_5_loss: 0.0376 - dense_out_6_loss: 0.0479 - dense_out_1_acc: 0.9832 - dense_out_2_acc: 0.9862 - dense_out_3_acc: 0.9855 - dense_out_4_acc: 0.9865 - dense_out_5_acc: 0.9884 - dense_out_6_acc: 0.9846 - val_loss: 4.1296 - val_dense_out_1_loss: 0.9833 - val_dense_out_2_loss: 0.9857 - val_dense_out_3_loss: 0.1334 - val_dense_out_4_loss: 0.0914 - val_dense_out_5_loss: 0.7607 - val_dense_out_6_loss: 1.1751 - val_dense_out_1_acc: 0.7827 - val_dense_out_2_acc: 0.7698 - val_dense_out_3_acc: 0.9705 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8453 - val_dense_out_6_acc: 0.7661\n",
      "Epoch 21/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2648 - dense_out_1_loss: 0.0470 - dense_out_2_loss: 0.0450 - dense_out_3_loss: 0.0404 - dense_out_4_loss: 0.0334 - dense_out_5_loss: 0.0485 - dense_out_6_loss: 0.0503 - dense_out_1_acc: 0.9853 - dense_out_2_acc: 0.9855 - dense_out_3_acc: 0.9872 - dense_out_4_acc: 0.9900 - dense_out_5_acc: 0.9851 - dense_out_6_acc: 0.9836 - val_loss: 4.2586 - val_dense_out_1_loss: 0.9853 - val_dense_out_2_loss: 1.0185 - val_dense_out_3_loss: 0.1571 - val_dense_out_4_loss: 0.1022 - val_dense_out_5_loss: 0.8148 - val_dense_out_6_loss: 1.1807 - val_dense_out_1_acc: 0.7827 - val_dense_out_2_acc: 0.7735 - val_dense_out_3_acc: 0.9613 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8361 - val_dense_out_6_acc: 0.7790\n",
      "Epoch 22/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2507 - dense_out_1_loss: 0.0463 - dense_out_2_loss: 0.0502 - dense_out_3_loss: 0.0461 - dense_out_4_loss: 0.0331 - dense_out_5_loss: 0.0358 - dense_out_6_loss: 0.0392 - dense_out_1_acc: 0.9824 - dense_out_2_acc: 0.9836 - dense_out_3_acc: 0.9834 - dense_out_4_acc: 0.9893 - dense_out_5_acc: 0.9896 - dense_out_6_acc: 0.9886 - val_loss: 4.2466 - val_dense_out_1_loss: 1.0242 - val_dense_out_2_loss: 0.9923 - val_dense_out_3_loss: 0.1388 - val_dense_out_4_loss: 0.0873 - val_dense_out_5_loss: 0.8201 - val_dense_out_6_loss: 1.1841 - val_dense_out_1_acc: 0.7680 - val_dense_out_2_acc: 0.7845 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8582 - val_dense_out_6_acc: 0.7551\n",
      "Epoch 23/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2528 - dense_out_1_loss: 0.0467 - dense_out_2_loss: 0.0525 - dense_out_3_loss: 0.0324 - dense_out_4_loss: 0.0302 - dense_out_5_loss: 0.0447 - dense_out_6_loss: 0.0463 - dense_out_1_acc: 0.9839 - dense_out_2_acc: 0.9843 - dense_out_3_acc: 0.9898 - dense_out_4_acc: 0.9900 - dense_out_5_acc: 0.9865 - dense_out_6_acc: 0.9841 - val_loss: 4.3370 - val_dense_out_1_loss: 0.9965 - val_dense_out_2_loss: 0.9789 - val_dense_out_3_loss: 0.1337 - val_dense_out_4_loss: 0.1112 - val_dense_out_5_loss: 0.8376 - val_dense_out_6_loss: 1.2791 - val_dense_out_1_acc: 0.7772 - val_dense_out_2_acc: 0.7753 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8435 - val_dense_out_6_acc: 0.7643\n",
      "Epoch 24/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2571 - dense_out_1_loss: 0.0498 - dense_out_2_loss: 0.0529 - dense_out_3_loss: 0.0358 - dense_out_4_loss: 0.0326 - dense_out_5_loss: 0.0351 - dense_out_6_loss: 0.0509 - dense_out_1_acc: 0.9829 - dense_out_2_acc: 0.9834 - dense_out_3_acc: 0.9881 - dense_out_4_acc: 0.9893 - dense_out_5_acc: 0.9893 - dense_out_6_acc: 0.9839 - val_loss: 4.1550 - val_dense_out_1_loss: 0.9384 - val_dense_out_2_loss: 1.0437 - val_dense_out_3_loss: 0.1080 - val_dense_out_4_loss: 0.0855 - val_dense_out_5_loss: 0.7839 - val_dense_out_6_loss: 1.1956 - val_dense_out_1_acc: 0.8085 - val_dense_out_2_acc: 0.7680 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8508 - val_dense_out_6_acc: 0.7661\n",
      "Avg_val_acc imporved from 0.8581952060966714 to 0.8594229570592818\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 25/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2981 - dense_out_1_loss: 0.0501 - dense_out_2_loss: 0.0538 - dense_out_3_loss: 0.0467 - dense_out_4_loss: 0.0370 - dense_out_5_loss: 0.0481 - dense_out_6_loss: 0.0624 - dense_out_1_acc: 0.9834 - dense_out_2_acc: 0.9832 - dense_out_3_acc: 0.9855 - dense_out_4_acc: 0.9896 - dense_out_5_acc: 0.9855 - dense_out_6_acc: 0.9805 - val_loss: 4.6623 - val_dense_out_1_loss: 1.0490 - val_dense_out_2_loss: 1.0777 - val_dense_out_3_loss: 0.1310 - val_dense_out_4_loss: 0.1078 - val_dense_out_5_loss: 0.8877 - val_dense_out_6_loss: 1.4090 - val_dense_out_1_acc: 0.7735 - val_dense_out_2_acc: 0.7698 - val_dense_out_3_acc: 0.9669 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8287 - val_dense_out_6_acc: 0.7330\n",
      "Epoch 26/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2643 - dense_out_1_loss: 0.0532 - dense_out_2_loss: 0.0525 - dense_out_3_loss: 0.0398 - dense_out_4_loss: 0.0299 - dense_out_5_loss: 0.0372 - dense_out_6_loss: 0.0517 - dense_out_1_acc: 0.9848 - dense_out_2_acc: 0.9848 - dense_out_3_acc: 0.9884 - dense_out_4_acc: 0.9877 - dense_out_5_acc: 0.9891 - dense_out_6_acc: 0.9846 - val_loss: 4.1682 - val_dense_out_1_loss: 0.9916 - val_dense_out_2_loss: 1.0316 - val_dense_out_3_loss: 0.1122 - val_dense_out_4_loss: 0.0999 - val_dense_out_5_loss: 0.7547 - val_dense_out_6_loss: 1.1783 - val_dense_out_1_acc: 0.7808 - val_dense_out_2_acc: 0.7753 - val_dense_out_3_acc: 0.9779 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8453 - val_dense_out_6_acc: 0.7643\n",
      "Epoch 27/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2448 - dense_out_1_loss: 0.0415 - dense_out_2_loss: 0.0526 - dense_out_3_loss: 0.0403 - dense_out_4_loss: 0.0416 - dense_out_5_loss: 0.0369 - dense_out_6_loss: 0.0319 - dense_out_1_acc: 0.9862 - dense_out_2_acc: 0.9855 - dense_out_3_acc: 0.9867 - dense_out_4_acc: 0.9865 - dense_out_5_acc: 0.9879 - dense_out_6_acc: 0.9912 - val_loss: 4.3637 - val_dense_out_1_loss: 0.9698 - val_dense_out_2_loss: 1.1192 - val_dense_out_3_loss: 0.1208 - val_dense_out_4_loss: 0.1079 - val_dense_out_5_loss: 0.8090 - val_dense_out_6_loss: 1.2369 - val_dense_out_1_acc: 0.7772 - val_dense_out_2_acc: 0.7661 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8379 - val_dense_out_6_acc: 0.7643\n",
      "Epoch 28/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2642 - dense_out_1_loss: 0.0429 - dense_out_2_loss: 0.0516 - dense_out_3_loss: 0.0318 - dense_out_4_loss: 0.0450 - dense_out_5_loss: 0.0471 - dense_out_6_loss: 0.0458 - dense_out_1_acc: 0.9860 - dense_out_2_acc: 0.9836 - dense_out_3_acc: 0.9896 - dense_out_4_acc: 0.9879 - dense_out_5_acc: 0.9851 - dense_out_6_acc: 0.9872 - val_loss: 4.2845 - val_dense_out_1_loss: 1.0276 - val_dense_out_2_loss: 1.0574 - val_dense_out_3_loss: 0.0935 - val_dense_out_4_loss: 0.0833 - val_dense_out_5_loss: 0.8168 - val_dense_out_6_loss: 1.2059 - val_dense_out_1_acc: 0.7716 - val_dense_out_2_acc: 0.7864 - val_dense_out_3_acc: 0.9761 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8416 - val_dense_out_6_acc: 0.7661\n",
      "Epoch 29/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2445 - dense_out_1_loss: 0.0513 - dense_out_2_loss: 0.0427 - dense_out_3_loss: 0.0416 - dense_out_4_loss: 0.0352 - dense_out_5_loss: 0.0331 - dense_out_6_loss: 0.0405 - dense_out_1_acc: 0.9843 - dense_out_2_acc: 0.9846 - dense_out_3_acc: 0.9865 - dense_out_4_acc: 0.9891 - dense_out_5_acc: 0.9917 - dense_out_6_acc: 0.9860 - val_loss: 4.3016 - val_dense_out_1_loss: 0.8923 - val_dense_out_2_loss: 1.1501 - val_dense_out_3_loss: 0.0807 - val_dense_out_4_loss: 0.0861 - val_dense_out_5_loss: 0.8424 - val_dense_out_6_loss: 1.2501 - val_dense_out_1_acc: 0.7974 - val_dense_out_2_acc: 0.7440 - val_dense_out_3_acc: 0.9816 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8324 - val_dense_out_6_acc: 0.7551\n",
      "Epoch 30/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2686 - dense_out_1_loss: 0.0489 - dense_out_2_loss: 0.0457 - dense_out_3_loss: 0.0444 - dense_out_4_loss: 0.0389 - dense_out_5_loss: 0.0434 - dense_out_6_loss: 0.0473 - dense_out_1_acc: 0.9834 - dense_out_2_acc: 0.9834 - dense_out_3_acc: 0.9851 - dense_out_4_acc: 0.9877 - dense_out_5_acc: 0.9846 - dense_out_6_acc: 0.9853 - val_loss: 4.5170 - val_dense_out_1_loss: 0.9801 - val_dense_out_2_loss: 1.0754 - val_dense_out_3_loss: 0.0995 - val_dense_out_4_loss: 0.1152 - val_dense_out_5_loss: 0.9522 - val_dense_out_6_loss: 1.2945 - val_dense_out_1_acc: 0.7716 - val_dense_out_2_acc: 0.7716 - val_dense_out_3_acc: 0.9797 - val_dense_out_4_acc: 0.9816 - val_dense_out_5_acc: 0.8232 - val_dense_out_6_acc: 0.7422\n",
      "Epoch 31/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2306 - dense_out_1_loss: 0.0462 - dense_out_2_loss: 0.0459 - dense_out_3_loss: 0.0364 - dense_out_4_loss: 0.0345 - dense_out_5_loss: 0.0315 - dense_out_6_loss: 0.0361 - dense_out_1_acc: 0.9865 - dense_out_2_acc: 0.9855 - dense_out_3_acc: 0.9886 - dense_out_4_acc: 0.9888 - dense_out_5_acc: 0.9898 - dense_out_6_acc: 0.9888 - val_loss: 5.0650 - val_dense_out_1_loss: 1.1560 - val_dense_out_2_loss: 1.2049 - val_dense_out_3_loss: 0.1290 - val_dense_out_4_loss: 0.1461 - val_dense_out_5_loss: 1.0424 - val_dense_out_6_loss: 1.3864 - val_dense_out_1_acc: 0.7477 - val_dense_out_2_acc: 0.7403 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9816 - val_dense_out_5_acc: 0.8029 - val_dense_out_6_acc: 0.7440\n",
      "Epoch 32/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2361 - dense_out_1_loss: 0.0481 - dense_out_2_loss: 0.0489 - dense_out_3_loss: 0.0365 - dense_out_4_loss: 0.0303 - dense_out_5_loss: 0.0323 - dense_out_6_loss: 0.0400 - dense_out_1_acc: 0.9851 - dense_out_2_acc: 0.9832 - dense_out_3_acc: 0.9874 - dense_out_4_acc: 0.9905 - dense_out_5_acc: 0.9898 - dense_out_6_acc: 0.9851 - val_loss: 4.1722 - val_dense_out_1_loss: 0.9541 - val_dense_out_2_loss: 1.0085 - val_dense_out_3_loss: 0.0682 - val_dense_out_4_loss: 0.0889 - val_dense_out_5_loss: 0.8499 - val_dense_out_6_loss: 1.2025 - val_dense_out_1_acc: 0.7845 - val_dense_out_2_acc: 0.7772 - val_dense_out_3_acc: 0.9779 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8214 - val_dense_out_6_acc: 0.7606\n",
      "Epoch 33/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2461 - dense_out_1_loss: 0.0451 - dense_out_2_loss: 0.0514 - dense_out_3_loss: 0.0381 - dense_out_4_loss: 0.0310 - dense_out_5_loss: 0.0402 - dense_out_6_loss: 0.0403 - dense_out_1_acc: 0.9870 - dense_out_2_acc: 0.9836 - dense_out_3_acc: 0.9886 - dense_out_4_acc: 0.9900 - dense_out_5_acc: 0.9858 - dense_out_6_acc: 0.9862 - val_loss: 3.9797 - val_dense_out_1_loss: 0.9140 - val_dense_out_2_loss: 0.9537 - val_dense_out_3_loss: 0.0988 - val_dense_out_4_loss: 0.0833 - val_dense_out_5_loss: 0.7794 - val_dense_out_6_loss: 1.1503 - val_dense_out_1_acc: 0.7790 - val_dense_out_2_acc: 0.7882 - val_dense_out_3_acc: 0.9853 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8564 - val_dense_out_6_acc: 0.7698\n",
      "Avg_val_acc imporved from 0.8594229570592818 to 0.8606507014723332\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 34/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2266 - dense_out_1_loss: 0.0436 - dense_out_2_loss: 0.0429 - dense_out_3_loss: 0.0386 - dense_out_4_loss: 0.0317 - dense_out_5_loss: 0.0342 - dense_out_6_loss: 0.0356 - dense_out_1_acc: 0.9853 - dense_out_2_acc: 0.9877 - dense_out_3_acc: 0.9867 - dense_out_4_acc: 0.9905 - dense_out_5_acc: 0.9886 - dense_out_6_acc: 0.9886 - val_loss: 3.8538 - val_dense_out_1_loss: 0.9119 - val_dense_out_2_loss: 0.9424 - val_dense_out_3_loss: 0.0673 - val_dense_out_4_loss: 0.0896 - val_dense_out_5_loss: 0.7530 - val_dense_out_6_loss: 1.0896 - val_dense_out_1_acc: 0.8066 - val_dense_out_2_acc: 0.7864 - val_dense_out_3_acc: 0.9816 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8343 - val_dense_out_6_acc: 0.7919\n",
      "Avg_val_acc imporved from 0.8606507014723332 to 0.8649478214624252\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 35/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2352 - dense_out_1_loss: 0.0533 - dense_out_2_loss: 0.0424 - dense_out_3_loss: 0.0378 - dense_out_4_loss: 0.0257 - dense_out_5_loss: 0.0435 - dense_out_6_loss: 0.0325 - dense_out_1_acc: 0.9829 - dense_out_2_acc: 0.9865 - dense_out_3_acc: 0.9874 - dense_out_4_acc: 0.9912 - dense_out_5_acc: 0.9858 - dense_out_6_acc: 0.9905 - val_loss: 4.0250 - val_dense_out_1_loss: 0.9469 - val_dense_out_2_loss: 1.0412 - val_dense_out_3_loss: 0.0928 - val_dense_out_4_loss: 0.0900 - val_dense_out_5_loss: 0.7111 - val_dense_out_6_loss: 1.1430 - val_dense_out_1_acc: 0.7790 - val_dense_out_2_acc: 0.7735 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9834 - val_dense_out_5_acc: 0.8527 - val_dense_out_6_acc: 0.7864\n",
      "Epoch 36/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2553 - dense_out_1_loss: 0.0437 - dense_out_2_loss: 0.0493 - dense_out_3_loss: 0.0375 - dense_out_4_loss: 0.0355 - dense_out_5_loss: 0.0401 - dense_out_6_loss: 0.0491 - dense_out_1_acc: 0.9853 - dense_out_2_acc: 0.9832 - dense_out_3_acc: 0.9853 - dense_out_4_acc: 0.9896 - dense_out_5_acc: 0.9867 - dense_out_6_acc: 0.9841 - val_loss: 3.9848 - val_dense_out_1_loss: 0.9071 - val_dense_out_2_loss: 0.9651 - val_dense_out_3_loss: 0.0853 - val_dense_out_4_loss: 0.0787 - val_dense_out_5_loss: 0.7845 - val_dense_out_6_loss: 1.1641 - val_dense_out_1_acc: 0.7956 - val_dense_out_2_acc: 0.7753 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8471 - val_dense_out_6_acc: 0.7790\n",
      "Epoch 37/300\n",
      "4215/4215 [==============================] - 36s 9ms/step - loss: 0.2257 - dense_out_1_loss: 0.0405 - dense_out_2_loss: 0.0406 - dense_out_3_loss: 0.0407 - dense_out_4_loss: 0.0229 - dense_out_5_loss: 0.0321 - dense_out_6_loss: 0.0489 - dense_out_1_acc: 0.9860 - dense_out_2_acc: 0.9886 - dense_out_3_acc: 0.9888 - dense_out_4_acc: 0.9917 - dense_out_5_acc: 0.9903 - dense_out_6_acc: 0.9855 - val_loss: 3.8480 - val_dense_out_1_loss: 0.8930 - val_dense_out_2_loss: 0.9340 - val_dense_out_3_loss: 0.1082 - val_dense_out_4_loss: 0.1033 - val_dense_out_5_loss: 0.7711 - val_dense_out_6_loss: 1.0384 - val_dense_out_1_acc: 0.7993 - val_dense_out_2_acc: 0.7956 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9834 - val_dense_out_5_acc: 0.8490 - val_dense_out_6_acc: 0.8011\n",
      "Avg_val_acc imporved from 0.8649478214624252 to 0.8670963789876653\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 38/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2315 - dense_out_1_loss: 0.0399 - dense_out_2_loss: 0.0501 - dense_out_3_loss: 0.0380 - dense_out_4_loss: 0.0298 - dense_out_5_loss: 0.0384 - dense_out_6_loss: 0.0353 - dense_out_1_acc: 0.9867 - dense_out_2_acc: 0.9848 - dense_out_3_acc: 0.9865 - dense_out_4_acc: 0.9931 - dense_out_5_acc: 0.9881 - dense_out_6_acc: 0.9912 - val_loss: 3.9479 - val_dense_out_1_loss: 0.8932 - val_dense_out_2_loss: 0.9460 - val_dense_out_3_loss: 0.1021 - val_dense_out_4_loss: 0.1094 - val_dense_out_5_loss: 0.7877 - val_dense_out_6_loss: 1.1094 - val_dense_out_1_acc: 0.8029 - val_dense_out_2_acc: 0.7827 - val_dense_out_3_acc: 0.9669 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8564 - val_dense_out_6_acc: 0.7937\n",
      "Epoch 39/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2009 - dense_out_1_loss: 0.0331 - dense_out_2_loss: 0.0383 - dense_out_3_loss: 0.0301 - dense_out_4_loss: 0.0365 - dense_out_5_loss: 0.0268 - dense_out_6_loss: 0.0362 - dense_out_1_acc: 0.9891 - dense_out_2_acc: 0.9877 - dense_out_3_acc: 0.9888 - dense_out_4_acc: 0.9884 - dense_out_5_acc: 0.9912 - dense_out_6_acc: 0.9884 - val_loss: 4.4790 - val_dense_out_1_loss: 0.9992 - val_dense_out_2_loss: 1.1056 - val_dense_out_3_loss: 0.1440 - val_dense_out_4_loss: 0.1306 - val_dense_out_5_loss: 0.9364 - val_dense_out_6_loss: 1.1631 - val_dense_out_1_acc: 0.7643 - val_dense_out_2_acc: 0.7551 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9834 - val_dense_out_5_acc: 0.8343 - val_dense_out_6_acc: 0.7937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2105 - dense_out_1_loss: 0.0335 - dense_out_2_loss: 0.0438 - dense_out_3_loss: 0.0364 - dense_out_4_loss: 0.0320 - dense_out_5_loss: 0.0321 - dense_out_6_loss: 0.0326 - dense_out_1_acc: 0.9893 - dense_out_2_acc: 0.9865 - dense_out_3_acc: 0.9884 - dense_out_4_acc: 0.9898 - dense_out_5_acc: 0.9898 - dense_out_6_acc: 0.9896 - val_loss: 3.8883 - val_dense_out_1_loss: 0.8906 - val_dense_out_2_loss: 0.9231 - val_dense_out_3_loss: 0.1094 - val_dense_out_4_loss: 0.0886 - val_dense_out_5_loss: 0.7933 - val_dense_out_6_loss: 1.0833 - val_dense_out_1_acc: 0.8103 - val_dense_out_2_acc: 0.7827 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8545 - val_dense_out_6_acc: 0.7956\n",
      "Avg_val_acc imporved from 0.8670963789876653 to 0.8674033131608208\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 41/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2274 - dense_out_1_loss: 0.0415 - dense_out_2_loss: 0.0405 - dense_out_3_loss: 0.0376 - dense_out_4_loss: 0.0353 - dense_out_5_loss: 0.0365 - dense_out_6_loss: 0.0361 - dense_out_1_acc: 0.9877 - dense_out_2_acc: 0.9886 - dense_out_3_acc: 0.9877 - dense_out_4_acc: 0.9884 - dense_out_5_acc: 0.9888 - dense_out_6_acc: 0.9888 - val_loss: 4.0675 - val_dense_out_1_loss: 0.9824 - val_dense_out_2_loss: 0.9985 - val_dense_out_3_loss: 0.1420 - val_dense_out_4_loss: 0.0954 - val_dense_out_5_loss: 0.7422 - val_dense_out_6_loss: 1.1070 - val_dense_out_1_acc: 0.7698 - val_dense_out_2_acc: 0.7827 - val_dense_out_3_acc: 0.9632 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8435 - val_dense_out_6_acc: 0.7974\n",
      "Epoch 42/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2264 - dense_out_1_loss: 0.0419 - dense_out_2_loss: 0.0415 - dense_out_3_loss: 0.0337 - dense_out_4_loss: 0.0344 - dense_out_5_loss: 0.0320 - dense_out_6_loss: 0.0429 - dense_out_1_acc: 0.9860 - dense_out_2_acc: 0.9862 - dense_out_3_acc: 0.9893 - dense_out_4_acc: 0.9900 - dense_out_5_acc: 0.9888 - dense_out_6_acc: 0.9870 - val_loss: 4.0214 - val_dense_out_1_loss: 0.9615 - val_dense_out_2_loss: 0.9229 - val_dense_out_3_loss: 0.1105 - val_dense_out_4_loss: 0.1109 - val_dense_out_5_loss: 0.7645 - val_dense_out_6_loss: 1.1510 - val_dense_out_1_acc: 0.7845 - val_dense_out_2_acc: 0.7882 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9908 - val_dense_out_5_acc: 0.8490 - val_dense_out_6_acc: 0.7993\n",
      "Epoch 43/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2012 - dense_out_1_loss: 0.0366 - dense_out_2_loss: 0.0393 - dense_out_3_loss: 0.0329 - dense_out_4_loss: 0.0249 - dense_out_5_loss: 0.0307 - dense_out_6_loss: 0.0368 - dense_out_1_acc: 0.9886 - dense_out_2_acc: 0.9879 - dense_out_3_acc: 0.9907 - dense_out_4_acc: 0.9912 - dense_out_5_acc: 0.9898 - dense_out_6_acc: 0.9893 - val_loss: 4.2443 - val_dense_out_1_loss: 0.9691 - val_dense_out_2_loss: 1.1082 - val_dense_out_3_loss: 0.1375 - val_dense_out_4_loss: 0.0883 - val_dense_out_5_loss: 0.7924 - val_dense_out_6_loss: 1.1487 - val_dense_out_1_acc: 0.7772 - val_dense_out_2_acc: 0.7790 - val_dense_out_3_acc: 0.9576 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8435 - val_dense_out_6_acc: 0.7790\n",
      "Epoch 44/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2236 - dense_out_1_loss: 0.0445 - dense_out_2_loss: 0.0406 - dense_out_3_loss: 0.0334 - dense_out_4_loss: 0.0290 - dense_out_5_loss: 0.0317 - dense_out_6_loss: 0.0444 - dense_out_1_acc: 0.9860 - dense_out_2_acc: 0.9870 - dense_out_3_acc: 0.9888 - dense_out_4_acc: 0.9929 - dense_out_5_acc: 0.9912 - dense_out_6_acc: 0.9862 - val_loss: 3.9381 - val_dense_out_1_loss: 0.9310 - val_dense_out_2_loss: 0.9511 - val_dense_out_3_loss: 0.1164 - val_dense_out_4_loss: 0.0880 - val_dense_out_5_loss: 0.7795 - val_dense_out_6_loss: 1.0721 - val_dense_out_1_acc: 0.7716 - val_dense_out_2_acc: 0.7790 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8600 - val_dense_out_6_acc: 0.7937\n",
      "Epoch 45/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2400 - dense_out_1_loss: 0.0482 - dense_out_2_loss: 0.0465 - dense_out_3_loss: 0.0356 - dense_out_4_loss: 0.0300 - dense_out_5_loss: 0.0396 - dense_out_6_loss: 0.0401 - dense_out_1_acc: 0.9851 - dense_out_2_acc: 0.9867 - dense_out_3_acc: 0.9893 - dense_out_4_acc: 0.9907 - dense_out_5_acc: 0.9867 - dense_out_6_acc: 0.9886 - val_loss: 4.7770 - val_dense_out_1_loss: 1.1602 - val_dense_out_2_loss: 1.0231 - val_dense_out_3_loss: 0.1164 - val_dense_out_4_loss: 0.1436 - val_dense_out_5_loss: 0.9876 - val_dense_out_6_loss: 1.3461 - val_dense_out_1_acc: 0.7348 - val_dense_out_2_acc: 0.7643 - val_dense_out_3_acc: 0.9705 - val_dense_out_4_acc: 0.9761 - val_dense_out_5_acc: 0.8122 - val_dense_out_6_acc: 0.7440\n",
      "Epoch 46/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2415 - dense_out_1_loss: 0.0460 - dense_out_2_loss: 0.0503 - dense_out_3_loss: 0.0309 - dense_out_4_loss: 0.0283 - dense_out_5_loss: 0.0408 - dense_out_6_loss: 0.0452 - dense_out_1_acc: 0.9853 - dense_out_2_acc: 0.9836 - dense_out_3_acc: 0.9879 - dense_out_4_acc: 0.9922 - dense_out_5_acc: 0.9867 - dense_out_6_acc: 0.9884 - val_loss: 4.0212 - val_dense_out_1_loss: 0.9358 - val_dense_out_2_loss: 0.8651 - val_dense_out_3_loss: 0.1129 - val_dense_out_4_loss: 0.0840 - val_dense_out_5_loss: 0.7918 - val_dense_out_6_loss: 1.2316 - val_dense_out_1_acc: 0.7919 - val_dense_out_2_acc: 0.7901 - val_dense_out_3_acc: 0.9761 - val_dense_out_4_acc: 0.9908 - val_dense_out_5_acc: 0.8379 - val_dense_out_6_acc: 0.7698\n",
      "Epoch 47/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2071 - dense_out_1_loss: 0.0387 - dense_out_2_loss: 0.0375 - dense_out_3_loss: 0.0338 - dense_out_4_loss: 0.0296 - dense_out_5_loss: 0.0344 - dense_out_6_loss: 0.0331 - dense_out_1_acc: 0.9879 - dense_out_2_acc: 0.9884 - dense_out_3_acc: 0.9891 - dense_out_4_acc: 0.9900 - dense_out_5_acc: 0.9884 - dense_out_6_acc: 0.9900 - val_loss: 3.9285 - val_dense_out_1_loss: 0.8526 - val_dense_out_2_loss: 0.8605 - val_dense_out_3_loss: 0.0725 - val_dense_out_4_loss: 0.0867 - val_dense_out_5_loss: 0.8050 - val_dense_out_6_loss: 1.2512 - val_dense_out_1_acc: 0.7937 - val_dense_out_2_acc: 0.7993 - val_dense_out_3_acc: 0.9853 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8453 - val_dense_out_6_acc: 0.7587\n",
      "Epoch 48/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2433 - dense_out_1_loss: 0.0482 - dense_out_2_loss: 0.0360 - dense_out_3_loss: 0.0348 - dense_out_4_loss: 0.0337 - dense_out_5_loss: 0.0395 - dense_out_6_loss: 0.0511 - dense_out_1_acc: 0.9860 - dense_out_2_acc: 0.9888 - dense_out_3_acc: 0.9860 - dense_out_4_acc: 0.9884 - dense_out_5_acc: 0.9888 - dense_out_6_acc: 0.9834 - val_loss: 4.3459 - val_dense_out_1_loss: 0.9207 - val_dense_out_2_loss: 0.8907 - val_dense_out_3_loss: 0.1141 - val_dense_out_4_loss: 0.0937 - val_dense_out_5_loss: 1.0247 - val_dense_out_6_loss: 1.3021 - val_dense_out_1_acc: 0.7937 - val_dense_out_2_acc: 0.8066 - val_dense_out_3_acc: 0.9797 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8103 - val_dense_out_6_acc: 0.7587\n",
      "Epoch 49/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2187 - dense_out_1_loss: 0.0389 - dense_out_2_loss: 0.0467 - dense_out_3_loss: 0.0317 - dense_out_4_loss: 0.0284 - dense_out_5_loss: 0.0396 - dense_out_6_loss: 0.0333 - dense_out_1_acc: 0.9874 - dense_out_2_acc: 0.9839 - dense_out_3_acc: 0.9891 - dense_out_4_acc: 0.9917 - dense_out_5_acc: 0.9877 - dense_out_6_acc: 0.9898 - val_loss: 4.0796 - val_dense_out_1_loss: 1.0368 - val_dense_out_2_loss: 0.8655 - val_dense_out_3_loss: 0.1462 - val_dense_out_4_loss: 0.0954 - val_dense_out_5_loss: 0.8231 - val_dense_out_6_loss: 1.1126 - val_dense_out_1_acc: 0.7698 - val_dense_out_2_acc: 0.7919 - val_dense_out_3_acc: 0.9705 - val_dense_out_4_acc: 0.9834 - val_dense_out_5_acc: 0.8361 - val_dense_out_6_acc: 0.7864\n",
      "Epoch 50/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2385 - dense_out_1_loss: 0.0488 - dense_out_2_loss: 0.0437 - dense_out_3_loss: 0.0379 - dense_out_4_loss: 0.0359 - dense_out_5_loss: 0.0315 - dense_out_6_loss: 0.0406 - dense_out_1_acc: 0.9843 - dense_out_2_acc: 0.9851 - dense_out_3_acc: 0.9900 - dense_out_4_acc: 0.9879 - dense_out_5_acc: 0.9903 - dense_out_6_acc: 0.9884 - val_loss: 4.2225 - val_dense_out_1_loss: 1.0535 - val_dense_out_2_loss: 0.8910 - val_dense_out_3_loss: 0.0952 - val_dense_out_4_loss: 0.0893 - val_dense_out_5_loss: 0.8626 - val_dense_out_6_loss: 1.2308 - val_dense_out_1_acc: 0.7569 - val_dense_out_2_acc: 0.8011 - val_dense_out_3_acc: 0.9705 - val_dense_out_4_acc: 0.9908 - val_dense_out_5_acc: 0.8453 - val_dense_out_6_acc: 0.7808\n",
      "Epoch 51/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2269 - dense_out_1_loss: 0.0504 - dense_out_2_loss: 0.0416 - dense_out_3_loss: 0.0326 - dense_out_4_loss: 0.0275 - dense_out_5_loss: 0.0313 - dense_out_6_loss: 0.0434 - dense_out_1_acc: 0.9865 - dense_out_2_acc: 0.9877 - dense_out_3_acc: 0.9888 - dense_out_4_acc: 0.9919 - dense_out_5_acc: 0.9900 - dense_out_6_acc: 0.9881 - val_loss: 4.2920 - val_dense_out_1_loss: 0.9139 - val_dense_out_2_loss: 0.9144 - val_dense_out_3_loss: 0.0924 - val_dense_out_4_loss: 0.1062 - val_dense_out_5_loss: 0.9494 - val_dense_out_6_loss: 1.3155 - val_dense_out_1_acc: 0.7827 - val_dense_out_2_acc: 0.7864 - val_dense_out_3_acc: 0.9797 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8214 - val_dense_out_6_acc: 0.7661\n",
      "Epoch 52/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2313 - dense_out_1_loss: 0.0439 - dense_out_2_loss: 0.0372 - dense_out_3_loss: 0.0402 - dense_out_4_loss: 0.0275 - dense_out_5_loss: 0.0406 - dense_out_6_loss: 0.0418 - dense_out_1_acc: 0.9867 - dense_out_2_acc: 0.9898 - dense_out_3_acc: 0.9879 - dense_out_4_acc: 0.9919 - dense_out_5_acc: 0.9886 - dense_out_6_acc: 0.9862 - val_loss: 4.0311 - val_dense_out_1_loss: 0.9422 - val_dense_out_2_loss: 0.8933 - val_dense_out_3_loss: 0.1025 - val_dense_out_4_loss: 0.1187 - val_dense_out_5_loss: 0.8139 - val_dense_out_6_loss: 1.1605 - val_dense_out_1_acc: 0.7772 - val_dense_out_2_acc: 0.7993 - val_dense_out_3_acc: 0.9797 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8398 - val_dense_out_6_acc: 0.7753\n",
      "Epoch 53/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2130 - dense_out_1_loss: 0.0451 - dense_out_2_loss: 0.0376 - dense_out_3_loss: 0.0344 - dense_out_4_loss: 0.0243 - dense_out_5_loss: 0.0304 - dense_out_6_loss: 0.0412 - dense_out_1_acc: 0.9846 - dense_out_2_acc: 0.9886 - dense_out_3_acc: 0.9888 - dense_out_4_acc: 0.9917 - dense_out_5_acc: 0.9900 - dense_out_6_acc: 0.9879 - val_loss: 4.2346 - val_dense_out_1_loss: 0.9500 - val_dense_out_2_loss: 0.9903 - val_dense_out_3_loss: 0.1521 - val_dense_out_4_loss: 0.0727 - val_dense_out_5_loss: 0.8532 - val_dense_out_6_loss: 1.2163 - val_dense_out_1_acc: 0.7919 - val_dense_out_2_acc: 0.7845 - val_dense_out_3_acc: 0.9595 - val_dense_out_4_acc: 0.9908 - val_dense_out_5_acc: 0.8508 - val_dense_out_6_acc: 0.7661\n",
      "Epoch 54/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2180 - dense_out_1_loss: 0.0418 - dense_out_2_loss: 0.0484 - dense_out_3_loss: 0.0358 - dense_out_4_loss: 0.0329 - dense_out_5_loss: 0.0256 - dense_out_6_loss: 0.0336 - dense_out_1_acc: 0.9858 - dense_out_2_acc: 0.9855 - dense_out_3_acc: 0.9886 - dense_out_4_acc: 0.9900 - dense_out_5_acc: 0.9896 - dense_out_6_acc: 0.9886 - val_loss: 3.8862 - val_dense_out_1_loss: 0.8455 - val_dense_out_2_loss: 0.8599 - val_dense_out_3_loss: 0.1027 - val_dense_out_4_loss: 0.0915 - val_dense_out_5_loss: 0.8270 - val_dense_out_6_loss: 1.1596 - val_dense_out_1_acc: 0.7919 - val_dense_out_2_acc: 0.8029 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8490 - val_dense_out_6_acc: 0.7716\n",
      "Epoch 55/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.1957 - dense_out_1_loss: 0.0413 - dense_out_2_loss: 0.0319 - dense_out_3_loss: 0.0340 - dense_out_4_loss: 0.0251 - dense_out_5_loss: 0.0326 - dense_out_6_loss: 0.0308 - dense_out_1_acc: 0.9881 - dense_out_2_acc: 0.9898 - dense_out_3_acc: 0.9886 - dense_out_4_acc: 0.9912 - dense_out_5_acc: 0.9905 - dense_out_6_acc: 0.9915 - val_loss: 3.8263 - val_dense_out_1_loss: 0.8348 - val_dense_out_2_loss: 0.7965 - val_dense_out_3_loss: 0.0896 - val_dense_out_4_loss: 0.0882 - val_dense_out_5_loss: 0.8127 - val_dense_out_6_loss: 1.2045 - val_dense_out_1_acc: 0.8140 - val_dense_out_2_acc: 0.8232 - val_dense_out_3_acc: 0.9853 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8435 - val_dense_out_6_acc: 0.7551\n",
      "Avg_val_acc imporved from 0.8674033131608208 to 0.8683241218822437\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 56/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2138 - dense_out_1_loss: 0.0349 - dense_out_2_loss: 0.0367 - dense_out_3_loss: 0.0398 - dense_out_4_loss: 0.0297 - dense_out_5_loss: 0.0419 - dense_out_6_loss: 0.0309 - dense_out_1_acc: 0.9893 - dense_out_2_acc: 0.9881 - dense_out_3_acc: 0.9888 - dense_out_4_acc: 0.9910 - dense_out_5_acc: 0.9867 - dense_out_6_acc: 0.9924 - val_loss: 4.3166 - val_dense_out_1_loss: 1.0060 - val_dense_out_2_loss: 0.8850 - val_dense_out_3_loss: 0.1262 - val_dense_out_4_loss: 0.1171 - val_dense_out_5_loss: 0.8738 - val_dense_out_6_loss: 1.3087 - val_dense_out_1_acc: 0.7772 - val_dense_out_2_acc: 0.8140 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8269 - val_dense_out_6_acc: 0.7532\n",
      "Epoch 57/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2351 - dense_out_1_loss: 0.0461 - dense_out_2_loss: 0.0469 - dense_out_3_loss: 0.0341 - dense_out_4_loss: 0.0354 - dense_out_5_loss: 0.0406 - dense_out_6_loss: 0.0320 - dense_out_1_acc: 0.9853 - dense_out_2_acc: 0.9846 - dense_out_3_acc: 0.9900 - dense_out_4_acc: 0.9900 - dense_out_5_acc: 0.9870 - dense_out_6_acc: 0.9888 - val_loss: 3.9946 - val_dense_out_1_loss: 0.8264 - val_dense_out_2_loss: 0.9569 - val_dense_out_3_loss: 0.1157 - val_dense_out_4_loss: 0.0904 - val_dense_out_5_loss: 0.8457 - val_dense_out_6_loss: 1.1594 - val_dense_out_1_acc: 0.8122 - val_dense_out_2_acc: 0.7974 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8398 - val_dense_out_6_acc: 0.7680\n",
      "Epoch 58/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2135 - dense_out_1_loss: 0.0484 - dense_out_2_loss: 0.0431 - dense_out_3_loss: 0.0332 - dense_out_4_loss: 0.0214 - dense_out_5_loss: 0.0302 - dense_out_6_loss: 0.0372 - dense_out_1_acc: 0.9877 - dense_out_2_acc: 0.9860 - dense_out_3_acc: 0.9900 - dense_out_4_acc: 0.9948 - dense_out_5_acc: 0.9910 - dense_out_6_acc: 0.9874 - val_loss: 3.6229 - val_dense_out_1_loss: 0.8276 - val_dense_out_2_loss: 0.7478 - val_dense_out_3_loss: 0.0958 - val_dense_out_4_loss: 0.1093 - val_dense_out_5_loss: 0.7625 - val_dense_out_6_loss: 1.0799 - val_dense_out_1_acc: 0.8066 - val_dense_out_2_acc: 0.8214 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8471 - val_dense_out_6_acc: 0.7901\n",
      "Avg_val_acc imporved from 0.8683241218822437 to 0.8707796164163422\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 59/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2125 - dense_out_1_loss: 0.0384 - dense_out_2_loss: 0.0429 - dense_out_3_loss: 0.0284 - dense_out_4_loss: 0.0282 - dense_out_5_loss: 0.0333 - dense_out_6_loss: 0.0413 - dense_out_1_acc: 0.9884 - dense_out_2_acc: 0.9870 - dense_out_3_acc: 0.9910 - dense_out_4_acc: 0.9917 - dense_out_5_acc: 0.9898 - dense_out_6_acc: 0.9853 - val_loss: 4.2500 - val_dense_out_1_loss: 1.0007 - val_dense_out_2_loss: 0.9835 - val_dense_out_3_loss: 0.1569 - val_dense_out_4_loss: 0.1206 - val_dense_out_5_loss: 0.8169 - val_dense_out_6_loss: 1.1714 - val_dense_out_1_acc: 0.7808 - val_dense_out_2_acc: 0.7901 - val_dense_out_3_acc: 0.9632 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8471 - val_dense_out_6_acc: 0.7919\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2289 - dense_out_1_loss: 0.0422 - dense_out_2_loss: 0.0415 - dense_out_3_loss: 0.0294 - dense_out_4_loss: 0.0343 - dense_out_5_loss: 0.0422 - dense_out_6_loss: 0.0392 - dense_out_1_acc: 0.9867 - dense_out_2_acc: 0.9877 - dense_out_3_acc: 0.9893 - dense_out_4_acc: 0.9877 - dense_out_5_acc: 0.9874 - dense_out_6_acc: 0.9877 - val_loss: 3.6863 - val_dense_out_1_loss: 0.8869 - val_dense_out_2_loss: 0.8484 - val_dense_out_3_loss: 0.1421 - val_dense_out_4_loss: 0.0707 - val_dense_out_5_loss: 0.7163 - val_dense_out_6_loss: 1.0220 - val_dense_out_1_acc: 0.7993 - val_dense_out_2_acc: 0.8085 - val_dense_out_3_acc: 0.9669 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8527 - val_dense_out_6_acc: 0.8103\n",
      "Avg_val_acc imporved from 0.8707796164163422 to 0.8707796177701616\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 61/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2009 - dense_out_1_loss: 0.0419 - dense_out_2_loss: 0.0361 - dense_out_3_loss: 0.0385 - dense_out_4_loss: 0.0253 - dense_out_5_loss: 0.0279 - dense_out_6_loss: 0.0311 - dense_out_1_acc: 0.9855 - dense_out_2_acc: 0.9893 - dense_out_3_acc: 0.9874 - dense_out_4_acc: 0.9910 - dense_out_5_acc: 0.9907 - dense_out_6_acc: 0.9910 - val_loss: 3.8175 - val_dense_out_1_loss: 0.9175 - val_dense_out_2_loss: 0.9060 - val_dense_out_3_loss: 0.1098 - val_dense_out_4_loss: 0.0884 - val_dense_out_5_loss: 0.7074 - val_dense_out_6_loss: 1.0883 - val_dense_out_1_acc: 0.7882 - val_dense_out_2_acc: 0.8011 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8656 - val_dense_out_6_acc: 0.7993\n",
      "Epoch 62/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2248 - dense_out_1_loss: 0.0420 - dense_out_2_loss: 0.0443 - dense_out_3_loss: 0.0340 - dense_out_4_loss: 0.0251 - dense_out_5_loss: 0.0379 - dense_out_6_loss: 0.0416 - dense_out_1_acc: 0.9867 - dense_out_2_acc: 0.9877 - dense_out_3_acc: 0.9905 - dense_out_4_acc: 0.9929 - dense_out_5_acc: 0.9886 - dense_out_6_acc: 0.9879 - val_loss: 4.0951 - val_dense_out_1_loss: 0.9826 - val_dense_out_2_loss: 0.8876 - val_dense_out_3_loss: 0.1145 - val_dense_out_4_loss: 0.1131 - val_dense_out_5_loss: 0.8038 - val_dense_out_6_loss: 1.1934 - val_dense_out_1_acc: 0.7974 - val_dense_out_2_acc: 0.8103 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8453 - val_dense_out_6_acc: 0.7974\n",
      "Epoch 63/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.1882 - dense_out_1_loss: 0.0348 - dense_out_2_loss: 0.0446 - dense_out_3_loss: 0.0312 - dense_out_4_loss: 0.0230 - dense_out_5_loss: 0.0288 - dense_out_6_loss: 0.0257 - dense_out_1_acc: 0.9896 - dense_out_2_acc: 0.9858 - dense_out_3_acc: 0.9891 - dense_out_4_acc: 0.9926 - dense_out_5_acc: 0.9919 - dense_out_6_acc: 0.9919 - val_loss: 4.0761 - val_dense_out_1_loss: 0.8345 - val_dense_out_2_loss: 0.9072 - val_dense_out_3_loss: 0.1065 - val_dense_out_4_loss: 0.1111 - val_dense_out_5_loss: 0.8379 - val_dense_out_6_loss: 1.2789 - val_dense_out_1_acc: 0.7974 - val_dense_out_2_acc: 0.8140 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9908 - val_dense_out_5_acc: 0.8398 - val_dense_out_6_acc: 0.7753\n",
      "Epoch 64/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.1746 - dense_out_1_loss: 0.0306 - dense_out_2_loss: 0.0321 - dense_out_3_loss: 0.0294 - dense_out_4_loss: 0.0266 - dense_out_5_loss: 0.0249 - dense_out_6_loss: 0.0310 - dense_out_1_acc: 0.9915 - dense_out_2_acc: 0.9898 - dense_out_3_acc: 0.9900 - dense_out_4_acc: 0.9934 - dense_out_5_acc: 0.9922 - dense_out_6_acc: 0.9903 - val_loss: 4.1921 - val_dense_out_1_loss: 0.9209 - val_dense_out_2_loss: 0.8761 - val_dense_out_3_loss: 0.1002 - val_dense_out_4_loss: 0.1174 - val_dense_out_5_loss: 0.8501 - val_dense_out_6_loss: 1.3273 - val_dense_out_1_acc: 0.7827 - val_dense_out_2_acc: 0.8250 - val_dense_out_3_acc: 0.9779 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8343 - val_dense_out_6_acc: 0.7624\n",
      "Epoch 65/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2190 - dense_out_1_loss: 0.0361 - dense_out_2_loss: 0.0409 - dense_out_3_loss: 0.0357 - dense_out_4_loss: 0.0271 - dense_out_5_loss: 0.0330 - dense_out_6_loss: 0.0462 - dense_out_1_acc: 0.9886 - dense_out_2_acc: 0.9872 - dense_out_3_acc: 0.9903 - dense_out_4_acc: 0.9903 - dense_out_5_acc: 0.9907 - dense_out_6_acc: 0.9836 - val_loss: 3.9816 - val_dense_out_1_loss: 0.8842 - val_dense_out_2_loss: 0.9372 - val_dense_out_3_loss: 0.1355 - val_dense_out_4_loss: 0.1154 - val_dense_out_5_loss: 0.7691 - val_dense_out_6_loss: 1.1400 - val_dense_out_1_acc: 0.8085 - val_dense_out_2_acc: 0.8195 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8416 - val_dense_out_6_acc: 0.7808\n",
      "Epoch 66/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2369 - dense_out_1_loss: 0.0588 - dense_out_2_loss: 0.0455 - dense_out_3_loss: 0.0336 - dense_out_4_loss: 0.0285 - dense_out_5_loss: 0.0320 - dense_out_6_loss: 0.0386 - dense_out_1_acc: 0.9824 - dense_out_2_acc: 0.9865 - dense_out_3_acc: 0.9896 - dense_out_4_acc: 0.9922 - dense_out_5_acc: 0.9884 - dense_out_6_acc: 0.9877 - val_loss: 4.2424 - val_dense_out_1_loss: 0.9037 - val_dense_out_2_loss: 0.9980 - val_dense_out_3_loss: 0.1209 - val_dense_out_4_loss: 0.1147 - val_dense_out_5_loss: 0.8170 - val_dense_out_6_loss: 1.2881 - val_dense_out_1_acc: 0.8048 - val_dense_out_2_acc: 0.8122 - val_dense_out_3_acc: 0.9761 - val_dense_out_4_acc: 0.9926 - val_dense_out_5_acc: 0.8435 - val_dense_out_6_acc: 0.7551\n",
      "Epoch 67/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2105 - dense_out_1_loss: 0.0353 - dense_out_2_loss: 0.0406 - dense_out_3_loss: 0.0279 - dense_out_4_loss: 0.0322 - dense_out_5_loss: 0.0369 - dense_out_6_loss: 0.0377 - dense_out_1_acc: 0.9896 - dense_out_2_acc: 0.9862 - dense_out_3_acc: 0.9910 - dense_out_4_acc: 0.9907 - dense_out_5_acc: 0.9879 - dense_out_6_acc: 0.9891 - val_loss: 3.7538 - val_dense_out_1_loss: 0.8257 - val_dense_out_2_loss: 0.8606 - val_dense_out_3_loss: 0.1160 - val_dense_out_4_loss: 0.1040 - val_dense_out_5_loss: 0.7430 - val_dense_out_6_loss: 1.1045 - val_dense_out_1_acc: 0.8379 - val_dense_out_2_acc: 0.8269 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8600 - val_dense_out_6_acc: 0.7864\n",
      "Avg_val_acc imporved from 0.8707796177701616 to 0.8787599702676138\n",
      "Saved model Models\\best_ConvLSTM_model_1_1553066490\n",
      "Epoch 68/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2251 - dense_out_1_loss: 0.0378 - dense_out_2_loss: 0.0436 - dense_out_3_loss: 0.0360 - dense_out_4_loss: 0.0334 - dense_out_5_loss: 0.0351 - dense_out_6_loss: 0.0392 - dense_out_1_acc: 0.9898 - dense_out_2_acc: 0.9862 - dense_out_3_acc: 0.9886 - dense_out_4_acc: 0.9896 - dense_out_5_acc: 0.9881 - dense_out_6_acc: 0.9865 - val_loss: 4.0719 - val_dense_out_1_loss: 0.9557 - val_dense_out_2_loss: 0.9841 - val_dense_out_3_loss: 0.1479 - val_dense_out_4_loss: 0.0992 - val_dense_out_5_loss: 0.7807 - val_dense_out_6_loss: 1.1043 - val_dense_out_1_acc: 0.7919 - val_dense_out_2_acc: 0.8177 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8490 - val_dense_out_6_acc: 0.7882\n",
      "Epoch 69/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2087 - dense_out_1_loss: 0.0417 - dense_out_2_loss: 0.0456 - dense_out_3_loss: 0.0276 - dense_out_4_loss: 0.0226 - dense_out_5_loss: 0.0311 - dense_out_6_loss: 0.0402 - dense_out_1_acc: 0.9877 - dense_out_2_acc: 0.9862 - dense_out_3_acc: 0.9912 - dense_out_4_acc: 0.9929 - dense_out_5_acc: 0.9898 - dense_out_6_acc: 0.9867 - val_loss: 4.1037 - val_dense_out_1_loss: 0.8872 - val_dense_out_2_loss: 0.9243 - val_dense_out_3_loss: 0.1188 - val_dense_out_4_loss: 0.1025 - val_dense_out_5_loss: 0.8544 - val_dense_out_6_loss: 1.2165 - val_dense_out_1_acc: 0.8103 - val_dense_out_2_acc: 0.8140 - val_dense_out_3_acc: 0.9761 - val_dense_out_4_acc: 0.9926 - val_dense_out_5_acc: 0.8435 - val_dense_out_6_acc: 0.7882\n",
      "Epoch 70/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2221 - dense_out_1_loss: 0.0407 - dense_out_2_loss: 0.0480 - dense_out_3_loss: 0.0331 - dense_out_4_loss: 0.0250 - dense_out_5_loss: 0.0345 - dense_out_6_loss: 0.0409 - dense_out_1_acc: 0.9872 - dense_out_2_acc: 0.9853 - dense_out_3_acc: 0.9907 - dense_out_4_acc: 0.9917 - dense_out_5_acc: 0.9900 - dense_out_6_acc: 0.9867 - val_loss: 3.9055 - val_dense_out_1_loss: 0.8539 - val_dense_out_2_loss: 0.9230 - val_dense_out_3_loss: 0.1497 - val_dense_out_4_loss: 0.1041 - val_dense_out_5_loss: 0.7316 - val_dense_out_6_loss: 1.1431 - val_dense_out_1_acc: 0.8140 - val_dense_out_2_acc: 0.8158 - val_dense_out_3_acc: 0.9705 - val_dense_out_4_acc: 0.9908 - val_dense_out_5_acc: 0.8692 - val_dense_out_6_acc: 0.7790\n",
      "Epoch 71/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2135 - dense_out_1_loss: 0.0372 - dense_out_2_loss: 0.0427 - dense_out_3_loss: 0.0324 - dense_out_4_loss: 0.0324 - dense_out_5_loss: 0.0354 - dense_out_6_loss: 0.0334 - dense_out_1_acc: 0.9896 - dense_out_2_acc: 0.9896 - dense_out_3_acc: 0.9912 - dense_out_4_acc: 0.9867 - dense_out_5_acc: 0.9896 - dense_out_6_acc: 0.9886 - val_loss: 3.8746 - val_dense_out_1_loss: 0.8888 - val_dense_out_2_loss: 0.8905 - val_dense_out_3_loss: 0.1213 - val_dense_out_4_loss: 0.0808 - val_dense_out_5_loss: 0.7787 - val_dense_out_6_loss: 1.1146 - val_dense_out_1_acc: 0.7882 - val_dense_out_2_acc: 0.7993 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9926 - val_dense_out_5_acc: 0.8545 - val_dense_out_6_acc: 0.7864\n",
      "Epoch 72/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.1951 - dense_out_1_loss: 0.0358 - dense_out_2_loss: 0.0414 - dense_out_3_loss: 0.0318 - dense_out_4_loss: 0.0267 - dense_out_5_loss: 0.0258 - dense_out_6_loss: 0.0336 - dense_out_1_acc: 0.9888 - dense_out_2_acc: 0.9872 - dense_out_3_acc: 0.9896 - dense_out_4_acc: 0.9900 - dense_out_5_acc: 0.9898 - dense_out_6_acc: 0.9884 - val_loss: 3.7186 - val_dense_out_1_loss: 0.8638 - val_dense_out_2_loss: 0.7915 - val_dense_out_3_loss: 0.1334 - val_dense_out_4_loss: 0.0909 - val_dense_out_5_loss: 0.7339 - val_dense_out_6_loss: 1.1051 - val_dense_out_1_acc: 0.8250 - val_dense_out_2_acc: 0.8287 - val_dense_out_3_acc: 0.9687 - val_dense_out_4_acc: 0.9908 - val_dense_out_5_acc: 0.8564 - val_dense_out_6_acc: 0.7845\n",
      "Epoch 73/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2139 - dense_out_1_loss: 0.0426 - dense_out_2_loss: 0.0438 - dense_out_3_loss: 0.0368 - dense_out_4_loss: 0.0299 - dense_out_5_loss: 0.0306 - dense_out_6_loss: 0.0302 - dense_out_1_acc: 0.9872 - dense_out_2_acc: 0.9853 - dense_out_3_acc: 0.9888 - dense_out_4_acc: 0.9893 - dense_out_5_acc: 0.9903 - dense_out_6_acc: 0.9891 - val_loss: 4.2461 - val_dense_out_1_loss: 0.9334 - val_dense_out_2_loss: 1.0013 - val_dense_out_3_loss: 0.1690 - val_dense_out_4_loss: 0.1296 - val_dense_out_5_loss: 0.8212 - val_dense_out_6_loss: 1.1916 - val_dense_out_1_acc: 0.8048 - val_dense_out_2_acc: 0.7974 - val_dense_out_3_acc: 0.9632 - val_dense_out_4_acc: 0.9816 - val_dense_out_5_acc: 0.8637 - val_dense_out_6_acc: 0.7753\n",
      "Epoch 74/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2065 - dense_out_1_loss: 0.0346 - dense_out_2_loss: 0.0340 - dense_out_3_loss: 0.0374 - dense_out_4_loss: 0.0317 - dense_out_5_loss: 0.0380 - dense_out_6_loss: 0.0308 - dense_out_1_acc: 0.9870 - dense_out_2_acc: 0.9888 - dense_out_3_acc: 0.9886 - dense_out_4_acc: 0.9903 - dense_out_5_acc: 0.9879 - dense_out_6_acc: 0.9886 - val_loss: 4.1882 - val_dense_out_1_loss: 0.8398 - val_dense_out_2_loss: 1.0075 - val_dense_out_3_loss: 0.1025 - val_dense_out_4_loss: 0.1018 - val_dense_out_5_loss: 0.8709 - val_dense_out_6_loss: 1.2657 - val_dense_out_1_acc: 0.8029 - val_dense_out_2_acc: 0.7845 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9890 - val_dense_out_5_acc: 0.8343 - val_dense_out_6_acc: 0.7735\n",
      "Epoch 75/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2000 - dense_out_1_loss: 0.0307 - dense_out_2_loss: 0.0438 - dense_out_3_loss: 0.0361 - dense_out_4_loss: 0.0217 - dense_out_5_loss: 0.0338 - dense_out_6_loss: 0.0338 - dense_out_1_acc: 0.9898 - dense_out_2_acc: 0.9867 - dense_out_3_acc: 0.9900 - dense_out_4_acc: 0.9936 - dense_out_5_acc: 0.9898 - dense_out_6_acc: 0.9893 - val_loss: 4.3559 - val_dense_out_1_loss: 0.8927 - val_dense_out_2_loss: 0.9958 - val_dense_out_3_loss: 0.1326 - val_dense_out_4_loss: 0.1137 - val_dense_out_5_loss: 0.9412 - val_dense_out_6_loss: 1.2799 - val_dense_out_1_acc: 0.8066 - val_dense_out_2_acc: 0.7901 - val_dense_out_3_acc: 0.9742 - val_dense_out_4_acc: 0.9853 - val_dense_out_5_acc: 0.8269 - val_dense_out_6_acc: 0.7698\n",
      "Epoch 76/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2080 - dense_out_1_loss: 0.0329 - dense_out_2_loss: 0.0449 - dense_out_3_loss: 0.0312 - dense_out_4_loss: 0.0254 - dense_out_5_loss: 0.0349 - dense_out_6_loss: 0.0386 - dense_out_1_acc: 0.9910 - dense_out_2_acc: 0.9862 - dense_out_3_acc: 0.9896 - dense_out_4_acc: 0.9919 - dense_out_5_acc: 0.9910 - dense_out_6_acc: 0.9862 - val_loss: 4.0466 - val_dense_out_1_loss: 0.8725 - val_dense_out_2_loss: 0.9467 - val_dense_out_3_loss: 0.1601 - val_dense_out_4_loss: 0.1169 - val_dense_out_5_loss: 0.8327 - val_dense_out_6_loss: 1.1178 - val_dense_out_1_acc: 0.7937 - val_dense_out_2_acc: 0.7956 - val_dense_out_3_acc: 0.9558 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8435 - val_dense_out_6_acc: 0.7901\n",
      "Epoch 77/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.2138 - dense_out_1_loss: 0.0416 - dense_out_2_loss: 0.0359 - dense_out_3_loss: 0.0327 - dense_out_4_loss: 0.0293 - dense_out_5_loss: 0.0380 - dense_out_6_loss: 0.0362 - dense_out_1_acc: 0.9877 - dense_out_2_acc: 0.9881 - dense_out_3_acc: 0.9896 - dense_out_4_acc: 0.9900 - dense_out_5_acc: 0.9893 - dense_out_6_acc: 0.9886 - val_loss: 4.3466 - val_dense_out_1_loss: 0.9197 - val_dense_out_2_loss: 1.0616 - val_dense_out_3_loss: 0.1393 - val_dense_out_4_loss: 0.1168 - val_dense_out_5_loss: 0.8432 - val_dense_out_6_loss: 1.2660 - val_dense_out_1_acc: 0.7937 - val_dense_out_2_acc: 0.7937 - val_dense_out_3_acc: 0.9724 - val_dense_out_4_acc: 0.9871 - val_dense_out_5_acc: 0.8398 - val_dense_out_6_acc: 0.7587\n",
      "Epoch 78/300\n",
      "4215/4215 [==============================] - 35s 8ms/step - loss: 0.1898 - dense_out_1_loss: 0.0343 - dense_out_2_loss: 0.0303 - dense_out_3_loss: 0.0305 - dense_out_4_loss: 0.0354 - dense_out_5_loss: 0.0264 - dense_out_6_loss: 0.0329 - dense_out_1_acc: 0.9881 - dense_out_2_acc: 0.9907 - dense_out_3_acc: 0.9898 - dense_out_4_acc: 0.9905 - dense_out_5_acc: 0.9917 - dense_out_6_acc: 0.9898 - val_loss: 3.9750 - val_dense_out_1_loss: 0.9343 - val_dense_out_2_loss: 0.9319 - val_dense_out_3_loss: 0.1768 - val_dense_out_4_loss: 0.1207 - val_dense_out_5_loss: 0.7392 - val_dense_out_6_loss: 1.0721 - val_dense_out_1_acc: 0.8250 - val_dense_out_2_acc: 0.8011 - val_dense_out_3_acc: 0.9632 - val_dense_out_4_acc: 0.9834 - val_dense_out_5_acc: 0.8656 - val_dense_out_6_acc: 0.7937\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 300\n",
    "NAME = 'ConvLSTM_model_1'\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "t = int(time.time())\n",
    "\n",
    "# checkpoint\n",
    "best_val_acc = 0\n",
    "chk_path = os.path.join(model_dir, 'best_{}_{}'.format(NAME,t))\n",
    "# checkpoint = ModelCheckpoint(chk_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "checkpoint = LambdaCallback(on_epoch_end=saveModel)\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}_{}\".format(NAME,t))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "history = model.fit(X_train, [y_train_0, y_train_1, y_train_2, y_train_3, y_train_4, y_train_5],\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "            validation_data=(X_val, [y_val_0, y_val_1, y_val_2, y_val_3, y_val_4, y_val_5]),\n",
    "            callbacks=callbacks_list)\n",
    "\n",
    "#Saving the model\n",
    "model.save(os.path.join(model_dir, 'final_{}_{}'.format(NAME,t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Models/best_ConvLSTM_model_1_1553066490')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = keras.backend.get_session()\n",
    "save_path\n",
    "keras.backend.get_session()\n",
    "saver.save(sess, 'Models/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred_0, y_pred_1, y_pred_2, y_pred_3, y_pred_4, y_pred_5) = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0 = np.argmax(y_pred_0, axis=1)\n",
    "y_pred_1 = np.argmax(y_pred_1, axis=1)\n",
    "y_pred_2 = np.argmax(y_pred_2, axis=1)\n",
    "y_pred_3 = np.argmax(y_pred_3, axis=1)\n",
    "y_pred_4 = np.argmax(y_pred_4, axis=1)\n",
    "y_pred_5 = np.argmax(y_pred_5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "true = []\n",
    "pred = []\n",
    "for i,code in enumerate(y_test_coded):\n",
    "    pred.append(labels_to_text([y_pred_0[i],y_pred_1[i],y_pred_2[i],y_pred_3[i],y_pred_4[i],y_pred_5[i]]))\n",
    "    true.append(labels_to_text(code))\n",
    "    if(pred[i] == true[i]):\n",
    "        acc = acc+1\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test_coded[:,0],y_pred_0)\n",
    "cm = cm/cm.sum(axis=0)\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in ['Left','Right','Legs','Tongue']],\n",
    "                  columns = [i for i in ['Left','Right','Legs','Tongue']])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8020050125313283\n",
      "0.8162071846282373\n",
      "0.9699248120300752\n",
      "0.9874686716791979\n",
      "0.8137009189640768\n",
      "0.783625730994152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_0 = accuracy_score(y_test_coded[:,0],y_pred_0)\n",
    "accuracy_1 = accuracy_score(y_test_coded[:,1],y_pred_1)\n",
    "accuracy_2 = accuracy_score(y_test_coded[:,2],y_pred_2)\n",
    "accuracy_3 = accuracy_score(y_test_coded[:,3],y_pred_3)\n",
    "accuracy_4 = accuracy_score(y_test_coded[:,4],y_pred_4)\n",
    "accuracy_5 = accuracy_score(y_test_coded[:,5],y_pred_5)\n",
    "print(accuracy_0)\n",
    "print(accuracy_1)\n",
    "print(accuracy_2)\n",
    "print(accuracy_3)\n",
    "print(accuracy_4)\n",
    "print(accuracy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 496, 1: 460, 2: 205, 3: 29, 4: 3, 5: 3, 6: 1})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = []\n",
    "for t,p in zip(true,pred):\n",
    "    ed.append(editdistance.eval(t,p))\n",
    "\n",
    "Counter(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter({1: 443, 2: 289, 0: 322, 4: 26, 3: 109, 5: 7, 6: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
